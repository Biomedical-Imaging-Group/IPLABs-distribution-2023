{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a869ed2e3db37aedbeb5775d5847cacc",
     "grade": false,
     "grade_id": "cell-da500ff8cea1b918",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing II</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=463\">MICRO-512</a>) taught by Dr. D. Sage, Dr. M. Liebling, Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL 2024.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay Lächler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguerón Arámburu</a>,\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>.\n",
    "     \n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 6.1: The wavelet transform</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: Monday 22 April, 2024</p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <span style=\"color:red\">Tuesday 30 April, 2024</span> (before 23:59) on <a href=\"https://moodle.epfl.ch/course/view.php?id=463\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Total number of points:</b> 19</p>\n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapter 8</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Student Name: \n",
    "\n",
    "### SCIPER: \n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e1e3c985eb3751b8faa1aeb83d38a13",
     "grade": true,
     "grade_id": "cell-fe844979884903ce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb4acc99c3fed7f8bde1719d08f881ad",
     "grade": false,
     "grade_id": "cell-b49b50603d5e20e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import standard Python libraries that we will use throughout the lab, as well as the following libraries that are required for the exercises:\n",
    "\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org/3.2.2/api/_as_gen/matplotlib.pyplot.html), to display images,\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive,\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays,\n",
    "* [OpenCV (`cv2`)](https://docs.opencv.org/2.4/index.html), for image processing tasks,\n",
    "* [`scipy.ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html), for more image processing tasks,\n",
    "* [PyWavelets (`pywt`)](https://pywavelets.readthedocs.io/en/latest/), to calculate wavelet transforms.\n",
    "\n",
    "Moreover, we will import the `ImageViewer` class (Python package developed specifically for these laboratories, see documentation [here](https://github.com/Biomedical-Imaging-Group/interactive-kit/wiki/Image-Viewer), or run the python command `help(viewer)` after loading the class), created specifically for this course, which provides interactive image visualization based on the `ipywidgets` library.\n",
    "\n",
    "As you can see, in this lab we will make an exception and import one library specific to the use of the wavelet transform, [PyWavelets](https://pywavelets.readthedocs.io/en/latest/). This is because this library gives us the most flexibility to work with the wavelet transform.\n",
    "\n",
    "Run the following cell to import all of these libraries and load the images we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60b0990cf17b23003118a756bacf27a3",
     "grade": false,
     "grade_id": "cell-e5e11f3d1fda5bfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import standard required packages for this exercise\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import ipywidgets as widgets\n",
    "import scipy.ndimage as ndi\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "import pywt\n",
    "import time\n",
    "from interactive_kit import imviewer as viewer\n",
    "from scipy import stats\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# Load images to be used in this exercise \n",
    "doisneau = cv.imread('images/doisneau.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "doisneau_noise = cv.imread('images/doisneau-noise.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "lowlight = cv.imread('images/lowlight.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "mer_de_glace = cv.imread('images/mer-de-glace.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "lighthouse = cv.imread('images/lighthouse.tif', cv.IMREAD_UNCHANGED).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "729df237317da0831b9fef15a0ab0d7b",
     "grade": false,
     "grade_id": "cell-4b72a2bcfd3b306d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The wavelet transform (10.5 points)\n",
    "\n",
    "In this laboratory we propose to study a simple *wavelet transform*, the **Haar wavelet transform**, and experiment with its applications. Moreover, you will develop the understanding and tools to experiment with any discrete wavelet transform you want. \n",
    "\n",
    "Note that the wavelet transform is itself an application of filtering and downsampling. While we expect you to be familiar and comfortable implementing the fundamental blocks in a low-level language, the lab will be completely in Python to simplify most tasks and allow you to focus on the _new_ content. If you would like to review the low-level implementations of filtering and downsampling, feel free to have a look at [Lab 2: Filtering](../2_Filtering_lab/1_Filtering.ipynb#-1.B.-Separable-version-(2-points)) and [Lab 1: Introductory](../0_Introductory_lab/Introductory.ipynb(#-2.A.a.-NumPy)).\n",
    "\n",
    "## <a id=\"ToC_1_WT\"></a>Table of contents\n",
    "1. [The Haar wavelet transform](#1.-The-Haar-wavelet-transform)\n",
    "    1. [Boundary conditions](#1.A.-Boundary-conditions)\n",
    "2. [Analysis](#2.-Analysis-(6-points))\n",
    "    1. [Filterbank implementation - Analysis](#2.A.-Filterbank-implementation---Analysis-(3-points)) **(3 points)**\n",
    "    2. [A note on the visualization of wavelet coefficients](#2.B.-A-note-on-the-visualization-of-wavelet-coefficients-(1-point)) **(1 point)**\n",
    "    3. [Polyphase implementation of the Haar wavelet transform - Analysis](#2.C.-Polyphase-implementation-of-the-Haar-wavelet-transform---Analysis-(1-point)) **(1 point)**\n",
    "    4. [PyWavelets - Analysis](#2.D.-PyWavelets---Analysis-(2-points)) **(2 points)**\n",
    "3. [Synthesis](#3.-Synthesis-(3-points)) \n",
    "    1. [Filterbank implementation - Synthesis](#3.A.-Filterbank-implementation---Synthesis-(2-points)) **(2 points)**\n",
    "    2. [Polyphase implementation of the Haar wavelet transform - Synthesis](#3.B-Polyphase-implementation-of-the-Haar-wavelet-transform---Synthesis-(1.5-point)) **(1.5 points)**\n",
    "    4. [Synthesis with PyWavelets](#3.C.-Synthesis-with-PyWavelets)\n",
    "    \n",
    "The overall algorithmic structure of the wavelet transform's filterbank implementation for scale $n=2$ is shown in the following figure.\n",
    "\n",
    "<center><img src=\"images/wavelet.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e112c9331fc9af68a32657ffe59d71ed",
     "grade": false,
     "grade_id": "cell-f3c9e0bd7846351c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize Images\n",
    "Feel free to get familiar now with the images you are going to use. Run the next cell and use `Next` / `Prev` to cycle through the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc1458bf1080d9aec8795fa9b398626b",
     "grade": false,
     "grade_id": "cell-7b2d0ecc9f20cfc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Display images\n",
    "image_list = [doisneau, doisneau_noise, lighthouse, mer_de_glace, lowlight]\n",
    "\n",
    "plt.close('all')\n",
    "imgs_viewer = viewer(image_list, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca0990ef171244497b4faa8d72bbdd59",
     "grade": false,
     "grade_id": "cell-a71e1b7af7131d8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. The Haar wavelet transform\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "## Introduction\n",
    "The Haar wavelet transform approximates a signal as a sum of alternating-sign piecewise constant functions at different shifts and scales.\n",
    "\n",
    "<center><img src=\"images/haar_showcase.png\" alt=\"Drawing\" style=\"width: 800px;\"/></center>\n",
    "\n",
    "Mathematically, this is just an example of what you have studied, where from a wavelet function $\\psi(x)$, a collection of basis functions is obtained as\n",
    "\n",
    "$$\\psi_{i,k}(x) = 2^{-\\frac{i}{2}}\\psi\\left(\\frac{x}{2^i}-k\\right)\\,, \\forall i \\in \\mathbb{N}, \\forall k \\in \\mathbb{Z}\\,,$$\n",
    "\n",
    "and any signal $f(x)$ can expanded as\n",
    "\n",
    "$$ f = \\sum_{i \\in \\mathbb{N}}\\sum_{k\\in\\mathbb{Z}} \\left\\langle f, \\psi_{i,k}\\right\\rangle \\psi_{i,k}\\,.$$\n",
    "\n",
    "In practice, this expansion is only applied up to a scale $i=n$, and for the shifts that are within the signal of interest.\n",
    "\n",
    "The discrete transformation splits a discrete signal of size $m$ into two parts of size $\\frac{m}{2}$, for example, $1$ and $1'$. When applied iteratively, the low frequency signal $1'$ is further split in into two parts, for example, $2$ and $2'$ of size $\\frac{m}{4}\\ldots$, as exemplified in the figure below for $n=3$.\n",
    "\n",
    "<center><img src=\"images/split_2.png\" alt=\"Drawing\" style=\"width: 1200px;\"/></center>\n",
    "\n",
    "Here, the frequency division is an idealized drawing to convey the concept, while in practice wavelet functions are not necessarily very sharp in the frequency domain. \n",
    "\n",
    "In the case of images (2 dimensional signals), the wavelet transform can be applied in a separable way. Because the wavelet transform decomposes the signal in low and high frequency content as seen above, a separable application results in four different regions on the wavelet coefficients for each scale, referred to as \n",
    " * *LL* for the low-frequency coefficients in both directions (typically placed in the upper-left corner),\n",
    " * *HL* for the high-frequency coefficients in the horizontal direction and low-frequency coefficients in the vertical direction (typically placed in the upper-right corner),\n",
    " * *LH* for the opposite of *HL* (typically placed in the lower-left corner), and\n",
    " * *HH* for the high-frequency coefficients in both directions (typically placed in the lower-right corner).\n",
    " \n",
    "When several iterations of the wavelet are applied, each iteration has its associated regions (**there is only one LL region, however**). These regions are subscripted according to the iteration they belong to, as shown in the image below.\n",
    "\n",
    "<center><img src=\"images/wavelet_orders.png\" alt=\"Drawing\" style=\"width: 350px;\"/></center>\n",
    "\n",
    "If `nx` and `ny` correspond to the size of the image in the $x$ and $y$ directions, respectively, each of the four regions are of size `nx/2`$\\times$`ny/2`. Together, they form an image of the same size as the original, as exemplified by the figure below.\n",
    "\n",
    "<center><img src=\"images/2dwt.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "931b56f5f136113e26731ec28490bf85",
     "grade": false,
     "grade_id": "cell-2f91b9a6e5e55e4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.A. Boundary conditions\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "In all the previous labs, we have used (and strongly recommended) *mirror* boundary conditions for applications in filtering (e.g., Gaussian smoothing or edge detection), which generally reduces boundary artifacts and results in images that are more pleasant to look at. \n",
    "\n",
    "However, when you apply a convolution with mirror or constant boundary conditions and clip the output to have the same length as the input, some information about the original signal is lost. This does not matter in most filtering applications - for example, in Gaussian filtering for denoising or edge detection, because you do not usually want to recover the original image. \n",
    "\n",
    "In contrast, in image *transforms* the inverse transform has a well defined meaning, and it is key for applications to be able to go back to the original domain without losing information. We do not care about how the signal looks **in the transform domain**, and we  **absolutely do not want any loss of information to occur, so that the original signal can be recovered**. This is why we use **periodic boundary conditions**. Intuitively, information *lost* in one boundary of an image is stored *on the other side of it*, and we can keep transforms of the same size as the original without losing any information. (Actually, using periodic boundary conditions, i.e., using circular convolutions, is exactly the same as filtering with the FFT of the same length of the signal.)\n",
    "\n",
    "Look at the following example of a one-dimensional wavelet transform taken with a full mode convolution (i.e. keeping all the coefficients of the convolution). Note how when the boundary conditions are set to constant, we need the values from outside the region of the original signal (limited by the vertical red lines) for the reconstruction. While when the boundary conditions are set to periodic, these values can be recovered from the other side of the signal, so we can have a wavelet transform of the exact same size as the signal. \n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Routing\" src=\"images/const_bound_wt.png\" width=\"400\"><br>\n",
    "    <em style=\"color: grey\">WT with full mode convolution and <b>constant</b> boundary conditions.</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img src=\"images/wrap_bound_wt.png\" alt=\"Drawing\" style=\"width: 400px;\"/><br>\n",
    "    <em style=\"color: grey\">WT with full mode convolution and <b>periodic</b> boundary conditions.</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "In the following sections, you will first implement the general wavelet transform in its filterbank formulation, using standard *NumPy* and *SciPy* functions. The resulting functions will be parameterized so that by simply providing the correct filters, you can evaluate any wavelet transform. After that, you will also implement the Haar wavelet transform using the *polyphase implementation*, which is more efficient, but less general. Finally, we will test your implementations with respect to the library *PyWavelets*, and teach you how to use it.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Notes:</b> To get a completely correct implementation fo the direct and inverse wavelet transforms, you will have to go through several steps:\n",
    "<ul>\n",
    "<li> you will have to get 4 filters right,</li>\n",
    "<li> you will have to implement two analysis functions (independent of each other, and only one of them dependent of the filters),</li>\n",
    "<li> you will have to implement two synthesis functions, similar to the analysis. </li>\n",
    "</ul>    \n",
    "We have designed <b>each section of the lab to be independent of the others</b>. For example, if you don't get the analysis function right, you will still be able to test the correctness of your synthesis, and we will grade them separately. \n",
    "    \n",
    "So, do not get stuck too long in a single exercise, as you will always be able to continue with the lab.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class = 'alert alert-warning'>\n",
    "\n",
    "<b>Hint:</b> A very common bug in this kind of lab is mixing up <code>nx</code> and <code>ny</code>. Some tests will be run in rectangular images, so you will catch the bug right away. However, some tests will also be done on square images, and you might miss this bug! Make sure to always make your own tests by creating cells wherever needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b4944fa642008d0f1e70a1b7394b8cd",
     "grade": false,
     "grade_id": "cell-220a76c72e41210c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Analysis (6 points) \n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "The analysis or direct wavelet transform is equivalent to obtaining the coefficients $\\left\\langle f, \\psi_{i,k}\\right\\rangle$ to express a signal $f$ in terms of the basis functions $\\psi_{i,k}$. As you can see in the [block diagram](#Index) of the filterbank implementation (not in the notation of the course), the analysis is carried out by applying two filters, which in the notation of the course are\n",
    " * $\\tilde{H}(z)$ for the low-pass filter, and \n",
    " * $\\tilde{G}(z)$ for the high-pass filter.\n",
    " \n",
    "In this section you will first implement the analysis using the filterbank implementation. Then we will make a short parenthesis to study how one can best visualize the wavelet transform coefficients. You will then proceed to the polyphase implementation of the Haar wavelet transform. Finally, you will test both your implementations against the implementation of *PyWavelets*. \n",
    "\n",
    "## 2.A. Filterbank implementation - Analysis (3 points)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "The filterbank implementation, during the analysis, uses two filters corresponding to a specific wavelet (highpass and lowpass filter), and consecutively applies the filtering and downsampling operations. Because this can be implemented very generically, the function you will now prepare will allow us to later experiment with different wavelets beyond Haar's. \n",
    "\n",
    "To begin this section, and **for 1 point,  write the impulse response of the four filters of the Haar filterbank (two for the analysis and two for the synthesis) in spatial domain (worth 0.25 each)**. \n",
    " **Give your answer as an numpy array with the minimum odd support necessary to clearly show the center of the filter**, considering that the value in the center is always assigned to $n=0$. \n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Example: </b> The filter $E(z)=\\pi(z-z^{-1})$ is implemented in the variable `example`, according to the reasoning in the table below, where $\\uparrow$ indicates the coefficient corresponding to $n=0$. Here, $\\delta[n]$ is the Kronecker delta centered at $0$.\n",
    "\n",
    "| $E(z)$ | $e[n]$ | $\\lbrace \\dots, \\underset{\\uparrow}{\\cdot}, \\dots \\rbrace$ | `example` | \n",
    "|--------|--------|-----------------------------------------------------|-----------|\n",
    "| $\\pi(z - z^{-1}) $ | $\\pi(\\delta[n+1] -\\delta[n-1])$ | $\\lbrace \\dots,0,\\pi,\\underset{\\uparrow}{0},-\\pi,0,\\dots\\rbrace$ | `np.array([np.pi, 0, -np.pi])` |\n",
    "\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69759b4bcf1d04adad49ffcbcc424139",
     "grade": false,
     "grade_id": "cell-9b5ce10714c2a5a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "analysis_lp = None\n",
    "analysis_hp = None\n",
    "synthesis_lp = None\n",
    "synthesis_hp = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e992b6eb0d6e26e5097d97b86576e3c6",
     "grade": true,
     "grade_id": "cell-76572217079cd10b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if not type(analysis_lp) == np.ndarray: print('WARNING!!\\nMake sure that you provide a NumPy array.')\n",
    "# size ...\n",
    "if not analysis_lp.size == 3: print('WARNING!!\\nEven though the filters of the Haar wavelet have a support of 2\\\n",
    "                                    elements, you need 3 elements to specify the center of the filter.')\n",
    "# and norm of your filters\n",
    "if not np.isclose(np.linalg.norm(analysis_lp), 1): print('WARNING!!\\nHint: all wavelet filters have a norm of 1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb58c98edb248c85426383e170eaedd2",
     "grade": true,
     "grade_id": "cell-594245d2d47cd84b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if not type(analysis_hp) == np.ndarray: print('WARNING!!\\nMake sure that you provide a NumPy array.')\n",
    "# size ...\n",
    "if not analysis_hp.size == 3: print('WARNING!!\\nEven though the filters of the Haar wavelet have a support of 2\\\n",
    "                                    elements, you need 3 elements to specify the center of the filter.')\n",
    "# and norm of your filters\n",
    "if not np.isclose(np.linalg.norm(analysis_hp), 1): print('WARNING!!\\nHint: all wavelet filters have a norm of 1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4db5f5900ee28b943cfa748781276594",
     "grade": true,
     "grade_id": "cell-6443de4936d1444a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if not type(synthesis_lp) == np.ndarray: print('WARNING!!\\nMake sure that you provide a NumPy array.')\n",
    "# size ...\n",
    "if not synthesis_lp.size == 3: print('WARNING!!\\nEven though the filters of the Haar wavelet have a support of 2\\\n",
    "                                    elements, you need 3 elements to specify the center of the filter.')\n",
    "# and norm of your filters\n",
    "if not np.isclose(np.linalg.norm(synthesis_lp), 1): print('WARNING!!\\nHint: all wavelet filters have a norm of 1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcb1238f386b900af080f3ca760ed25f",
     "grade": true,
     "grade_id": "cell-ea048dd0d058f183",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if not type(synthesis_hp) == np.ndarray: print('WARNING!!\\nMake sure that you provide a NumPy array.')\n",
    "# size ...\n",
    "if not synthesis_hp.size == 3: print('WARNING!!\\nEven though the filters of the Haar wavelet have a support of 2\\\n",
    "                                    elements, you need 3 elements to specify the center of the filter.')\n",
    "# and norm of your filters\n",
    "if not np.isclose(np.linalg.norm(synthesis_hp), 1): print('WARNING!!\\nHint: all wavelet filters have a norm of 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b657a4528ddd3cd7e340aa2140e60730",
     "grade": false,
     "grade_id": "cell-8233f1b48a61b6b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id=\"filt_impl_anal\"></a>Now, **for 2 points**, implement the filterbank implementation of the analysis part of the wavelet transform in Python by completing the function `analysis` below, which takes as parameters\n",
    "\n",
    "* `data`: the original image,\n",
    "* `lp`: the low-pass analysis filter,\n",
    "* `hp`: the high-pass analysis filter,\n",
    "* `n`: the number of iterations of the analysis filterbank to perform, i.e., the maximum _scale_ to be used.\n",
    "\n",
    "The output is the wavelet transform, a 2D NumPy array of the same size as the original image.\n",
    " \n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Hints:</b>\n",
    "    \n",
    "<ul>\n",
    " <li>For convolution, use <code>ndi.convolve1d</code> (<a href='https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve1d.html#scipy.ndimage.convolve1d'>see documentation</a>) which applies a horizontal/vertical 1D convolution to all the rows/columns of an image simultaneously along the specified axis, which is why we use it instead of <a href='https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html'><code>scipy.signal.convolve2d</code></a> (<b>which we will not accept</b>). Moreover, <code>ndi.convolve1d</code> gives the result of the same size as the input, so you will not have to worry about the convolution mode.</li>\n",
    " <li>Use periodic boundary conditions for <code>ndi.convolve1d</code>. </li>\n",
    " <li>For downsampling, use <a href='https://numpy.org/doc/stable/reference/arrays.indexing.html'>NumPy slicing</a>, notation: <code>[start:stop:step]</code>. In the next cell you will see an example where we downsample a $10\\times 10$ array. </li> \n",
    " <li> To <i>construct</i> the wavelet transform coefficients (i.e., join <i>L</i> and <i>H</i> coefficients as shown in the images in <a href=\"#1.-The-Haar-wavelet-transform\" >Section 1</a>, use the <a href='https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html'><code>np.concatenate</code></a> function. </li>\n",
    "<li> When calling each of these functions, be very careful with the <code>axis</code> parameter.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f27cfccae34d9c6f92503261bb767c0",
     "grade": false,
     "grade_id": "cell-220369de2f0ce6c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Declare test image\n",
    "test = np.arange(100).reshape((10,10))\n",
    "print('Original array: \\n', test)\n",
    "# Downsampling in the horizontal direction\n",
    "print('\\n Horizontally downsampled array: \\n', test[:, ::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "498a300a480d4d216bf1df1d06ad86b9",
     "grade": false,
     "grade_id": "cell-e5bdc88960ba293c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the analysis part of the wavelet transform on img\n",
    "def analysis(img, lp, hp, n):\n",
    "    # Get dimensions of the original image\n",
    "    ny, nx = img.shape\n",
    "    # Declare output\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Get LL (will select the whole image the first time, and \n",
    "        # the LL part of the previous iteration the next times)\n",
    "        sub = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable sub, which is incorporated\n",
    "        # into output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal transform\n",
    "        # Apply filters to create the two horizontal components\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Downsample\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Concatenate results to construct horizontal wavelet structure\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## Vertical transform\n",
    "        # Repeat all the steps above for the vertical transform\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Insert sub to replace the old LL coefficients\n",
    "        output[0:ny, 0:nx] = sub\n",
    "        # Adjust dimensions to represent the new LL coefficient\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3af040032033d1f42e3f7592a1b2a809",
     "grade": false,
     "grade_id": "cell-7de1fe9dc5d9572d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will apply your function to the image `lowlight` with $n = 1$ and wth $n = 4$. Make sure that the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae56126259a53b6d8c08cf4f710ba2a8",
     "grade": true,
     "grade_id": "cell-96c7aa39150af48e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we apply the wavelet transform to the image lowlight\n",
    "lowlight_wt_1 = analysis(lowlight, analysis_lp, analysis_hp, 1)\n",
    "lowlight_wt_3 = analysis(lowlight, analysis_lp, analysis_hp, 3)\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([lowlight_wt_1, lowlight_wt_3], title=['n = 1', 'n = 3'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c131a5b6d590a0fa00ef621ea47e757f",
     "grade": false,
     "grade_id": "cell-98dd1ff20104866b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What do you think about the result? Let's apply your function to a rectangular image now. We will test on `mer_de_glace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8466c6135fabd9cbb389ac7b15ddeb8",
     "grade": true,
     "grade_id": "cell-63c61dfffae18ed0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mer_de_glace_wt_1 = analysis(mer_de_glace, analysis_lp, analysis_hp, 1)\n",
    "mer_de_glace_wt_3 = analysis(mer_de_glace, analysis_lp, analysis_hp, 3)\n",
    "\n",
    "rect_viewer = viewer([mer_de_glace_wt_1, mer_de_glace_wt_3], title=['n = 1', 'n = 3'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "353e53d1d93c75c79b77e13d50c6ab47",
     "grade": false,
     "grade_id": "cell-fcf1d97402752832",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.B. A note on the visualization of wavelet coefficients (1 point)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "As you probably just noticed, the contrast obtained when displaying the wavelet transform is not ideal. This is because the low frequency coefficients are almost always much larger than the high frequency coefficients. Many colormaps have been proposed to enhance the visualization of the wavelet transform. These colormaps, in general,\n",
    "\n",
    "* treat the different regions of the wavelet transform (*LL*, *HL*, *LH*, *HH*) as independent images, and\n",
    "* keep the $0$ value of the coefficients at the same level throughout the image.\n",
    "\n",
    "In this section we will see two possible visualization techniques:\n",
    "\n",
    "1. `Non-uniform mapping`: \n",
    "\n",
    "Negative values are linearly mapped to the range $[0, 127.5]$, and the positive values to $[127.5, 255]$. $0$ is mapped to $127.5$. This implies that positive and negative numbers are not treated equally (they go through different linear transformations).\n",
    "\n",
    "2. `Normalized standard deviation mapping`: \n",
    "\n",
    "The image is first scaled so that its standard deviation $\\sigma=1$, then clipped to the range $[\\overline{x}-3\\sigma, \\overline{x}+3\\sigma]$ (where $\\overline{x}$ represents the sample mean of the data, and $\\sigma=1$ its sample standard deviation) to avoid outliers that reduce overall contrast.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Important:</b> These colormaps are only for visualization purposes. Be careful not to confuse their output with the output of the wavelet transform. \n",
    "</div>\n",
    "\n",
    "In the next cell, we provide the first colormap, `non_uniform_map`. For **1 point**, you will have to implement the second one, `norm_std_map`. \n",
    "\n",
    "<div class = 'alert alert-warning'>\n",
    "\n",
    "<b>Note:</b> <b>We do not take answers with nested loops iterating through every element of a NumPy Array as correct</b>.\n",
    "</div>\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "<b>Hint:</b> In the case where the $\\sigma$ of the image is 0, (e.g. a constant image), no operation is needed, return the original image. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34eaaffd5d3a031d61495241e316b67",
     "grade": false,
     "grade_id": "cell-304f7e89e114ae8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Non-uniform color-map\n",
    "def non_uniform_map(img):\n",
    "    # Initialize with a copy of the input image\n",
    "    output = np.copy(img)    \n",
    "    # Avoid the case in which the minimum of the image is 0 \n",
    "    # (in which case the negative mapping is not necessary, as it would not be applied anywhere)\n",
    "    img_min = np.min(img)\n",
    "    if img_min < 0:\n",
    "        # Min maps to 0, 0 maps to 127.5\n",
    "        output[img<0] = 127.5/(-img_min) * (img[img<0] - img_min)\n",
    "    # Avoid the case in which the maximum of the image is 0 \n",
    "    # (in which case the positive mapping is not necessary, as it would not be applied anywhere)\n",
    "    img_max = np.max(img)\n",
    "    if img_max > 0:\n",
    "        # 0 maps to 127.5, max maps to 255\n",
    "        output[img>0] = 127.5 + 127.5*img[img>0]/img_max\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Normalize std color-map\n",
    "def norm_std_map(img):\n",
    "    # Initialize with a copy of the input image\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7bcc882ca19e39a5c12918f4c907090",
     "grade": false,
     "grade_id": "cell-4a4cc3bd613268a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before we go any further, let's design a small test for you to make sure that your function `norm_std_map` is correct. We will create $10^4$ points sampled from a [normal distributtion](https://en.wikipedia.org/wiki/Normal_distribution), using your *SCIPER* to determine the parameters of the distribution. For the purpose, we will use the function [numpy.random.randn](https://en.wikipedia.org/wiki/Normal_distribution). \n",
    "\n",
    "Then we will apply your function `norm_std_map`, and show you the histograms, means, and standard deviations of both arrays in a plot. Moreover, we will print the first indices where the original and mapped arrays are fairly close to $0$. \n",
    "    \n",
    "Use this plot to try to verify that everything is right. \n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note:</b> Remember that these tests by no means guarantee the points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4bf5e0d3b1e682c0af141ce32fcc4cb",
     "grade": true,
     "grade_id": "cell-5ce37360b5719f10",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed and distribution parameters using your SCIPER\n",
    "np.random.seed(uid)\n",
    "mean = uid % 3 + 2 \n",
    "std = uid % 5 + 3\n",
    "\n",
    "# Generate random array and apply your function\n",
    "# if it fails, it is likely because the code has not been vectorized\n",
    "rand_arr = mean + std * np.random.randn(10000)\n",
    "try:\n",
    "    arr_mapped = norm_std_map(rand_arr)\n",
    "except TypeError:\n",
    "    print('WARNING!!\\nBe sure to avoid nested loops in your answers! These are considered incorrect.')\n",
    "\n",
    "print(f'The near-zero-level of the original array is found first at index \\\n",
    "{np.where(np.abs(rand_arr) == np.min(np.abs(rand_arr)))[0][0]}.\\n')\n",
    "print(f'The near-zero-level of the colormapped array is found first at index \\\n",
    "{np.where(np.abs(arr_mapped) == np.min(np.abs(arr_mapped)))[0][0]}.\\n\\nUse this information carefully, remember that this is a random process.')\n",
    "\n",
    "# Extract statistics from both arrays\n",
    "rand_arr_mean = rand_arr.mean(); rand_arr_std = rand_arr.std()\n",
    "arr_mapped_mean = arr_mapped.mean(); arr_mapped_std = arr_mapped.std()\n",
    "# Plot\n",
    "plt.close('all')\n",
    "# Define bins\n",
    "bins = np.linspace(mean - 3 * std , mean + 3 * std, 100)\n",
    "# Plot original array and statistics\n",
    "plt.figure(figsize = (9, 4))\n",
    "plt.hist(rand_arr, bins, alpha=0.5, color='aquamarine', label=r'Original array $\\mathbf{x}$')\n",
    "xticks = plt.xticks()[0]; plt.xticks(np.sort(np.hstack((xticks,[-2,-1,0,1,2]))))\n",
    "plt.axvline(rand_arr_mean, color='g', linestyle='-.', alpha=0.5, linewidth=2, label=r'$\\hat{\\mu}_x = \\sum x_i / N$')\n",
    "plt.axvline(rand_arr_mean + rand_arr_std, color='g', linestyle='-.', linewidth=0.8, label=r'$\\pm\\hat{\\sigma}_x$')\n",
    "plt.axvline(rand_arr_mean - rand_arr_std, color='g', linestyle='-.', linewidth=0.8)\n",
    "# Plot transformed array and statistics\n",
    "plt.hist(arr_mapped, bins, alpha=0.5, color='gray', label=r'Normalized array $\\mathbf{y}$')\n",
    "plt.axvline(arr_mapped_mean, color='k', linestyle='dashed', alpha=0.5, linewidth=2, label=r'$\\hat{\\mu}_y = \\sum y_i /N$')\n",
    "plt.axvline(arr_mapped_mean + arr_mapped_std, color='k', linestyle='dashed', linewidth=0.8, label=r'$\\pm\\hat{\\sigma}_y$')\n",
    "plt.axvline(arr_mapped_mean - arr_mapped_std, color='k', linestyle='dashed', linewidth=0.8)\n",
    "plt.legend(loc='upper right'); plt.title('Normalized standard deviation colormap')\n",
    "plt.xlabel('Values'); plt.ylabel('Count'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "479c3ea14fdb3a4b9ef6d4371ff65af0",
     "grade": false,
     "grade_id": "cell-a125a72268ec0bc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does the histogram above make sense? Make sure that the your transformation matches what we described and that everything seems to work. Now, run the next cell for some sanity tests. We will check that\n",
    "\n",
    " * the standard deviation of the result is $1$, and \n",
    " * that you treated the case of a constant array (`std=0`) properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68c425058aefc63e0e7be9a3d4b5025a",
     "grade": false,
     "grade_id": "cell-01e9c3fbb9044527",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test if std=1\n",
    "np.testing.assert_almost_equal(1, arr_mapped_std, decimal=2,\n",
    "                               err_msg='The standard deviation of the second array is not 1!')\n",
    "# Test zero std image \n",
    "z_arr_mapped = norm_std_map(np.ones((1000)))\n",
    "assert not np.any(z_arr_mapped == np.inf) or np.all(z_arr_mapped == 0.), 'You did not treat the case where the std is 0 correctly.'\n",
    "print('Nice, your function passed the sanity check!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d77c5bdeada895c597dc64a58d567eda",
     "grade": false,
     "grade_id": "cell-522ead00c6be77cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to apply your colormap to each coefficient of the Haar wavelet transform separately, we define the function `map_color()`, which takes as input a transformed image, the number of iterations $n$ of the transform and the color-map. Run the next cell to declare this function.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Hint:</b> Even though you do not have to code anything in the following cell, you should take a look at how we extract the regions of the wavelet transform. It might prove useful later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b8947ecaf0d2f82c45de059210d4697",
     "grade": true,
     "grade_id": "cell-6d4b80bf419ae3da",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Applies the color_map to the wavelet transform img with n iterations\n",
    "def map_color(img, n=0, color_map=np.array):\n",
    "    # This first block is to determine whether we have a raw image or the color_map\n",
    "    div = 2**(n)\n",
    "    # ny and nx represent the size of the LL coefficient of the last iteration of analysis\n",
    "    ny, nx = np.array(img.shape) // div\n",
    "    \n",
    "    # Generate output array to work on\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # First we apply the color-map to LL coefficients\n",
    "    # if n = 0, we're applying the colormap to the whole image\n",
    "    output[0:ny, 0:nx] = color_map(output[0:ny, 0:nx])\n",
    "    # Now we will iterate through the number of WT iterations and process the other three regions for each scale\n",
    "    # if n = 0, the loop will not start\n",
    "    for i in range(n):\n",
    "        # Apply color_map to high-frequency components\n",
    "        output[0:ny, nx:2*nx] = color_map(output[0:ny, nx:2*nx])\n",
    "        output[ny:2*ny, nx:2*nx] = color_map(output[ny:2*ny, nx:2*nx])\n",
    "        output[ny:2*ny, 0:nx] = color_map(output[ny:2*ny, 0:nx])\n",
    "        \n",
    "        # Update dimensions\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45d99514df78ea450159b79f0d63df43",
     "grade": false,
     "grade_id": "cell-dea2b66c268672fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to visualize your results again, this time apply the colormap of your choice.\n",
    "<div class = 'alert alert-success'>\n",
    "\n",
    "<b>Note:</b> In the next cell, you can choose which mapping you want to use by assigning one of the color-map functions to the variable <code>color_map</code>. If you select <code>color_map = np.array</code>, no color-map will be applied. If you feel creative, you can even define your own color-map! The color-map you choose here will be used throughout the lab, but you can always come back and change it. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Choose one of the colormap functions\n",
    "# color_map = norm_std_map\n",
    "color_map = non_uniform_map\n",
    "# color_map = np.array \n",
    "\n",
    "# Apply the wavelet transform to the image lowlight\n",
    "lowlight_wt_1 = analysis(lowlight, analysis_lp, analysis_hp, 1)\n",
    "lowlight_wt_3 = analysis(lowlight, analysis_lp, analysis_hp, 3)\n",
    "# Apply the color-map\n",
    "mapped_wt_1 = map_color(lowlight_wt_1, n=1, color_map=color_map)\n",
    "mapped_wt_3 = map_color(lowlight_wt_3, n=3, color_map=color_map)\n",
    "# Define parameters of viewer\n",
    "image_list = [lowlight, mapped_wt_1, mapped_wt_3]\n",
    "title_list = ['Original', 'Wavelet transform (n = 1)', 'Wavelet transform (n = 3)']\n",
    "# Display the result\n",
    "plt.close('all')\n",
    "analysis_viewer = viewer(image_list, title=title_list, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84c9d1ceebdae10fc3ee157bf3a43c75",
     "grade": false,
     "grade_id": "cell-2dcd52d4661a6b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which one did you prefer? As you can see, both make the presence of noise more evident than using a colormap proportional to the raw wavelet transform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c12f15523b91ba6afaec495a1f0a47f2",
     "grade": false,
     "grade_id": "cell-611a276920e54420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.C. Polyphase implementation of the Haar wavelet transform - Analysis (1 point) \n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "In this section you will implement a fast version of the Haar wavelet transform. The key insight here is that in the filterbank implementation, half the computations made in the convolutions are thrown away immediately after by downsampling. \n",
    "\n",
    "In a polyphase implementation, we save computations by downsampling copies of the signal with different shifts first and then applying equivalent filters. For the Haar wavelet transform, this results in the following formula for the one-dimensional transform\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    y_1[k] \\\\ y_2[k] \n",
    "\\end{bmatrix} = \\frac{1}{\\sqrt{2}}\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    1 & -1 \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "    x[2k] \\\\\n",
    "    x[2k+1] \n",
    "\\end{bmatrix}\\,.$$\n",
    "\n",
    "Here, $y_1[k]$ and $y_2[k]$ represent the low-pass and high-pass wavelet coefficients, and $x[k]$ represents the one-dimensional signal (a row/column of the image when doing our horizontal/vertical pass).  \n",
    "\n",
    "This will save both code complexity and computation time.  **For 1 point**, complete the function `poly_analysis` in the next cell. The structure is very similar to the one described in the filterbank implementation ([Section 2.A](#2.A.-Filterbank-implementation-(3-points))).\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Note:</b>\n",
    "    <ul>\n",
    "        <li>The expression above does not necessarily need to be implemented as a matrix multiplication.</li>\n",
    "        <li>Looping through rows/columns/pixels is not allowed.</li>\n",
    "        <li>Do not use <code>ndi.convolve1d</code> here.</li>\n",
    "    </ul>    \n",
    "</div>\n",
    "<div class = 'alert alert-warning'>\n",
    "    \n",
    "<b>Note:</b> Depending of your implementation, you might come up across several bugs. A known one is due to Python copying mechanisms (if you assign a NumPy Array to another NumPy Array, and apply an operation to the former, the latter one will also be modified). Try wrapping suspicious assignments with <code>np.copy()</code>. For the curious, this happens because internally, NumPy mostly <a href=\"https://realpython.com/python-pass-by-reference/\">assigns by reference instead of assigning by value</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0db7d8172e2f156190dd896f8d690752",
     "grade": false,
     "grade_id": "cell-4ba8bcf7d6994449",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def poly_analysis(img, n):\n",
    "    # Get dimensions of original\n",
    "    ny, nx = img.shape\n",
    "    # Declare output\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Get LL (will select the whole image the first time, and\n",
    "        # the LL part of the previous iteration the next times)\n",
    "        sub = np.copy(output[0:ny, 0:nx])\n",
    "        \n",
    "        # Store your result in the variable sub, which is incorporated\n",
    "        # into output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal transform\n",
    "        # Separate even and odd horizontal coefficients\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Compute y_1[k] and y_2[k] from the expression above \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Concatenate results to create horizontal wavelet transfrom\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## Vertical transform\n",
    "        # Repeat all the steps above for the vertical transform\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        output[0:ny, 0:nx] = sub \n",
    "        # Adjust dimensions of LL coefficient\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcc0fce41ae465b613c69eeb8100f707",
     "grade": false,
     "grade_id": "cell-93260646237ee86e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You are really becoming an expert on wavelet transforms! As an initial visual test, we will almost copy-paste the cell you had right after the filterbank implementation (*spoiler:* the result should be the same, except that now we are using the visualization you selected).\n",
    "\n",
    "Run the next cell to plot the result of the function `poly_analysis` applied to the image lowlight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acfe6bb366c664b0eb2089b61c99c9e0",
     "grade": true,
     "grade_id": "cell-09879518045f5eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we apply the Wavelet Transform to the image lowlight\n",
    "lowlight_wt_1 = poly_analysis(lowlight, 1)\n",
    "lowlight_wt_3 = poly_analysis(lowlight, 3)\n",
    "# Apply the color-map\n",
    "mapped_wt_1 = map_color(lowlight_wt_1, n=1, color_map=color_map)\n",
    "mapped_wt_3 = map_color(lowlight_wt_3, n=3, color_map=color_map)\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([mapped_wt_1, mapped_wt_3], title=['Wavelet transform - Polyphase (n = 1)', 'Wavelet transform - Polyphase (n = 3)'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fe1268713d772f3026d33bd0a5e057a",
     "grade": false,
     "grade_id": "cell-f4074df175d4aeb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you feel confident about both your implementations, we have a test to check that the polyphase formulation is in fact faster than the filterbank implementation.\n",
    "\n",
    "Run the next cell to see the difference averaged over $10$ runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef809bc3ad52046edde989b222de27d2",
     "grade": false,
     "grade_id": "cell-32e18866b43f2c1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scales = np.arange(1,10,dtype=np.float32)\n",
    "time_poly = np.zeros_like(scales); time_filterbank = np.zeros_like(scales)\n",
    "reps = 10\n",
    "# Run test\n",
    "for n in scales:\n",
    "    for i in range(reps):\n",
    "        # Measure polyphase time\n",
    "        start = time.time()\n",
    "        poly = poly_analysis(doisneau, int(n))\n",
    "        end = time.time()\n",
    "        time_poly_run = end - start\n",
    "        # Measure filterbank time\n",
    "        start = time.time()\n",
    "        filterbank = analysis(doisneau, analysis_lp, analysis_hp, int(n))\n",
    "        end = time.time()\n",
    "        time_filterbank_run = end - start\n",
    "        # Update times\n",
    "        time_poly[int(n)-1] += time_poly_run/reps\n",
    "        time_filterbank[int(n)-1] += time_filterbank_run/reps\n",
    "\n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.plot(scales, 1000*time_filterbank, label=\"Standard implementation [ms]\")\n",
    "plt.plot(scales, 1000*time_poly, label=\"Polyphase implementation [ms]\")\n",
    "plt.xlabel(r\"Scale $n$\"); plt.ylabel(r\"ms\")\n",
    "plt.legend();\n",
    "\n",
    "print(f\"On average, the polyphase implementation is {np.mean(time_filterbank)/np.mean(time_poly):.2f} times faster \\\n",
    "than the standard filterbank across the different scales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "971f1ec79d3e6ddc48075561ff3322ff",
     "grade": false,
     "grade_id": "cell-10c4e7d4f7909385",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.D. PyWavelets - Analysis (2 points)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "To finish this section, we will show you how to do this step with [PyWavelets](https://pywavelets.readthedocs.io/en/latest/) and provide numerical tests for both your implementations.  The functions we will use are [`pywt.dwt2`](https://pywavelets.readthedocs.io/en/latest/ref/2d-dwt-and-idwt.html#single-level-dwt2) and [`pywt.idwt2`](https://pywavelets.readthedocs.io/en/latest/ref/2d-dwt-and-idwt.html#single-level-idwt2), which stand for discrete wavelet transform and inverse discrete wavelet transform in 2D. The basic syntax of `pywt.dwt2` is\n",
    "\n",
    "```python\n",
    "cA, (cV, cH, cD) = pywt.dwt2(data, wavelet='haar', mode='periodization')\n",
    "```\n",
    "\n",
    "The parameters are\n",
    "* `data`: the image,\n",
    "* `wavelet` (a string): which wavelet to use (find [here](https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html#wavelet-families) a list of the available wavelets),\n",
    "* `mode`: we will use `'periodization'` This is the only mode that ensures that we can have a perfect synthesis (see [options](https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes)). The default `mode` is `'symmetric'`, so make sure to always change it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2906d6e6ef7622f145efbf0d837dbd38",
     "grade": false,
     "grade_id": "cell-be26557cb7b788ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "For **1 point**, map the output of the function `pywt.dwt2` with the four components LL, LH, HL, HH by changing the value `None` to a string, e.g. `'LL'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bfb1392c3dc6e012ae2dfb5b0036464",
     "grade": false,
     "grade_id": "cell-451855ac7dd7b313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cA = None\n",
    "cV= None\n",
    "cH = None\n",
    "cD = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a515b361d16b12095deacb1c202f4aca",
     "grade": true,
     "grade_id": "cell-bb81433e23328857",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if type(cA) is not str: print('WARNING!!\\nMake sure that you provide a string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecd8fd29cadd5bc3ba2759bb074f3aac",
     "grade": true,
     "grade_id": "cell-8a2ab77b192b2877",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if type(cV) is not str: print('WARNING!!\\nMake sure that you provide a string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1dbedc873e8d52c3e44959e5808c9d6",
     "grade": true,
     "grade_id": "cell-c4d81ee4c217ccfc",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if type(cH) is not str: print('WARNING!!\\nMake sure that you provide a string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc1a3c1c71f6220958f9c49f64610b5f",
     "grade": true,
     "grade_id": "cell-7effe9f95b591eb4",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check for type...\n",
    "if type(cD) is not str: print('WARNING!!\\nMake sure that you provide a string.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb49e2f0a02265aa683aff1a79c244d7",
     "grade": false,
     "grade_id": "cell-d2d01c532a9b0b61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "In the next cell, we will provide the function `pywt_analysis(img, n, wavelet)` which will perform $n$ iterations of the wavelet transform using PyWavelets and outputs a single image consistent with your previous results. Thus, the parameters are\n",
    "\n",
    "* `data`: the image,\n",
    "* `n`: order of the wavelet transform,\n",
    "* `wavelet` (string): which wavelet to use (find [here](https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html#wavelet-families) a list of the available wavelets).\n",
    "\n",
    "Run the next cell to declare this function and apply it to the image `lowlight` for $n = 1$, and $n = 3$.  Explore the results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62bebf35bd52a49669670c8f427d55e4",
     "grade": false,
     "grade_id": "cell-d819170d40f5324a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the wavelet transform on img using PyWavelets\n",
    "def pywt_analysis(img, n, wavelet):\n",
    "    # Extract image shape\n",
    "    ny, nx = img.shape\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Extract image or LL coefficients\n",
    "        sub = output[0:ny, 0:nx]\n",
    "        # Get analysis coefficients with PyWavelets\n",
    "        cA, (cV, cH, cD) = pywt.dwt2(sub, wavelet=wavelet, mode='periodization')\n",
    "        # Update size of LL coefficients\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "        # Fill output with results\n",
    "        output[0:ny, 0:nx] = cA\n",
    "        output[ny:2*ny, 0:nx] = cV\n",
    "        output[0:ny, nx:2*nx] = cH\n",
    "        output[ny:2*ny, nx:2*nx] = cD\n",
    "    return output\n",
    "\n",
    "# Apply the analysis and color-map\n",
    "lowlight_wt_1 = pywt_analysis(lowlight, 1, 'haar')\n",
    "lowlight_wt_1 = map_color(lowlight_wt_1, n=1, color_map=color_map)\n",
    "lowlight_wt_3 = pywt_analysis(lowlight, 3, 'haar')\n",
    "lowlight_wt_3 = map_color(lowlight_wt_3, n=3, color_map=color_map)\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([lowlight_wt_1, lowlight_wt_3], title=['Wavelet transform - PyWavelets (n = 1)', 'Wavelet transform - PyWavelets (n = 3)'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11f5027429fe006a934825d6cc826d3a",
     "grade": false,
     "grade_id": "cell-6fd953cc3d427b94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, you will get the final test for both implementations, an element-wise comparison of the output of `analysis`, `poly_analysis` and `pywt_analysis`, up to the $10^{th}$ decimal (so yeah, equal). Moreover, the filterbank implementation will also be tested on the Daubechies 2 wavelet (DB2) - we define the appropriate filters in the same cell. If the following cell runs without any error, congratulations, your implementations match the results of PyWavelets!\n",
    "\n",
    "In case your implementation is not correct, the next cell will also plot the wrong results. To get a hint on where you went wrong, we are using the *compare* function of ImageViewer. Look for the red regions in the images for details (these regions are where your results and PyWavelets' differ). Note that you can activate the comparison again after changing images by clicking on `Options` $\\rightarrow$ `Compare`.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note:</b> As usual, the fact that this cell runs does not guarantee the points.\n",
    "</div>\n",
    "\n",
    "If you see these red regions and need to debug your implementation, you can go back to [section 2.A](#filt_impl_anal) (filterbank implementation) or [section 2.C](#2.C.-Polyphase-implementation-of-the-Haar-wavelet-transform---Analysis-(1-point)) to debug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd6fdbf08f257cac94ad7855839672a8",
     "grade": false,
     "grade_id": "cell-a76aacda7a0c154d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define n\n",
    "n = 2\n",
    "\n",
    "## Test Haar\n",
    "# Get the results of the three wavelet transform implementations\n",
    "lighthouse_pywt = pywt_analysis(lighthouse, n, 'haar')\n",
    "lighthouse_poly = poly_analysis(lighthouse, n)\n",
    "lighthouse_filt = analysis(lighthouse, analysis_lp, analysis_hp, n)\n",
    "\n",
    "# Test polyphase implementation\n",
    "error_haar = False\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_pywt, lighthouse_poly, decimal=10)\n",
    "except Exception as e:\n",
    "    print('Your polyphase implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True\n",
    "    plt.close('all')\n",
    "    viewer([lighthouse_poly,lighthouse_pywt],\n",
    "           title = [\"Polyphase\", \"PyWavelets (Ground truth)\"], compare=True, widgets=True)\n",
    "\n",
    "# Test standard filterbank implementation\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_pywt, lighthouse_filt, decimal=10)\n",
    "except Exception as e:\n",
    "    print('Either your filterbank implementation is not correct, or your Haar filters are not correct (check the \\\n",
    "           test with DB2 filters to know for sure). Look at the following message for details.\\n')\n",
    "    error_haar = True\n",
    "    print(e)\n",
    "    viewer([lighthouse_filt, lighthouse_pywt],\n",
    "           title = [\"Filterbank Implementation\", \"PyWavelets (Ground truth)\"], compare=True, widgets=True)\n",
    "        \n",
    "## Test DB2\n",
    "# Set the coefficients \n",
    "a = (1 + np.sqrt(3))/(4*np.sqrt(2)); b = (3 + np.sqrt(3))/(4*np.sqrt(2))\n",
    "c = (3 - np.sqrt(3))/(4*np.sqrt(2)); d = (1 - np.sqrt(3))/(4*np.sqrt(2))\n",
    "# Define the filters\n",
    "analysis_lp_db2  = np.array([d, c, b, a, 0]); analysis_hp_db2  = np.array([-a, b, -c, d, 0])\n",
    "synthesis_lp_db2 = np.array([0, a, b, c, d]); synthesis_hp_db2 = np.array([0, d, -c, b, -a])\n",
    "\n",
    "# Test\n",
    "error_db = False\n",
    "lighthouse_filt_db2 = analysis(lighthouse, analysis_lp_db2, analysis_hp_db2, n=n)\n",
    "lighthouse_pywt_db2 = pywt_analysis(lighthouse, n, 'db2')\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_filt_db2, lighthouse_pywt_db2, decimal=10)\n",
    "    if error_haar:\n",
    "        print('Your filterbank implementation is correct, but you should check your Haar filters.')        \n",
    "except Exception as e:\n",
    "    print('Your filterbank implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_db = True\n",
    "    viewer([lighthouse_filt_db2,lighthouse_pywt_db2], title=[\"Filterbank (DB2)\", \"PyWavelets (Ground truth)\"], \n",
    "           compare=True)\n",
    "\n",
    "if not(error_db or error_haar):\n",
    "    print('Congratulations! You are as good as the most accepted wavelet library in Python.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77b718bc633716567b7950303041708b",
     "grade": false,
     "grade_id": "cell-9536b99b641d0a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To finish this section, we want you to play with the maximum scale $n$, the colormap applied, and the selection of wavelet used in the analysis. We will use the function we defined previously, `pywt_analysis()`, and extra widgets in the **ImageViewer** to do this.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<b>Note:</b> We didn't list all the available wavelets, of course! To get a detailed description of the wavelets available by PyWavelets, you can go to <a href=\"http://wavelets.pybytes.com/wavelet/db4/\">this site</a> of the PyWavelets documentation. Note that we didn't cover every one of them in the course! Moreover, the site by PyWavelets can be overwhelming. For a quick overview of each of the families, Mathworks has <a href=\"https://www.mathworks.com/help/wavelet/gs/introduction-to-the-wavelet-families.html\">this</a> very good introduction, and <a href=\"https://www.mathworks.com/help/wavelet/ug/wavelet-families-additional-discussion.html\">this</a> also very good additional discussion. \n",
    "    \n",
    "If you are interested in exploring the wavelet transform for time series and other one-dimensional data, you can also look at <a href=\"http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\">this post</a> for a practically-oriented introduction to wavelets with Python. \n",
    "    \n",
    "Finally, if you want to go further into the topic, your course notes have a lot of academic material. Furthermore, you can check out the series of <a href=\"http://bigwww.epfl.ch/tutorials/index.html?k=wavelets\">books, talks and tutorials</a> by the Biomedical Imaging Group, which cover from the theory of wavelets to numerous applications in image denoising (that you will also do in the second part of the lab) and reconstruction.\n",
    "</div>\n",
    "\n",
    "In particular, we have added\n",
    "* the *n* slider: a slider to choose the number of scales,\n",
    "* the wavelet dropdown menu: a menu to choose among several wavelet transforms to apply,\n",
    "* the `Mapping` dropdown menu: a dropdown menu to choose whether (and which) colormap to use to enhance the visualization of the coefficients, and\n",
    "* the button `Analysis` to apply your selection.\n",
    "\n",
    "Remember to go the the menu `Extra Widgets` to access the options described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb23edd468ab258090c968fe5c80dc7f",
     "grade": false,
     "grade_id": "cell-d7628145a7b77664",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_slider = widgets.IntSlider(value=1, min=0, max=5, step=1, description='n') \n",
    "wt_menu = widgets.Dropdown(options=['haar', 'db2', 'db10', 'bior1.3', 'bior6.8', 'rbio1.3', 'dmey'], \n",
    "                                value='haar', description='WT:')\n",
    "mapping_menu = widgets.Dropdown(options=['None', 'Normalize std', 'Non-uniform map'], \n",
    "                                value='None', description='Mapping:')\n",
    "button = widgets.Button(description='Analysis')\n",
    "\n",
    "def wavelet_callback(img):\n",
    "    n = n_slider.value\n",
    "    wt = wt_menu.value\n",
    "    output = pywt_analysis(img, n, wt)\n",
    "    if mapping_menu.value == 'None':\n",
    "        output = map_color(output, n=n, color_map=np.array)\n",
    "    elif mapping_menu.value == 'Normalize std':\n",
    "        output = map_color(output, n=n, color_map=norm_std_map)\n",
    "    else:\n",
    "        output = map_color(output, n=n, color_map=non_uniform_map)\n",
    "    return output\n",
    "\n",
    "wavelet_viewer = viewer(mer_de_glace, title=\"WT Analysis\", \n",
    "                        new_widgets=[n_slider, wt_menu, mapping_menu, button], \n",
    "                        callbacks=[wavelet_callback], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87762d6912a66b76d5cfa83296b2303c",
     "grade": false,
     "grade_id": "cell-0684a05795e13e00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you want to experiment with different images, orders, etc., use the next cell and recycle any code you want! This may also help you answer the multiple choice question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec5f73dc0c074d03e4d60318cc331f2c",
     "grade": false,
     "grade_id": "cell-22fc3d0ca14efea8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice question\n",
    "\n",
    "To finish this section, answer the next *MCQ*, **worth 1 point**.\n",
    "\n",
    "* Q1: How does the wavelet transform of a white noise image look?\n",
    "    \n",
    "    1. The LL coefficients have much higher values than all the others, as usual.\n",
    "    2. The HH coefficients have much higher values than all the others, because uncorrelated random noise contains extremely high frequencies.\n",
    "    3. The LL, LH, HL, and HH coefficients have similar values because white noise is spread equally across frequencies.\n",
    "    4. The LH and HL coefficients have lower values than the LL and HH coefficients, because random diagonal frequency components (high or low frequency) are very unlikely.\n",
    "    \n",
    "In the next cell, modify the variable `answer` to reflect your answers. The following cells is for you to check that your answer is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6f4e52265175e4a4fba37bea9a2c4f",
     "grade": false,
     "grade_id": "cell-6f6fc7cf27e68da6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify the variable answer\n",
    "answer = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98f907d48e08c80a6f8e285b722187ae",
     "grade": true,
     "grade_id": "cell-1876cdadf4184d24",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if not answer in [1, 2, 3, 4]:\n",
    "    print('WARNING!!\\nChoose one of 1, 2, 3 or 4. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3c84bf17c0dce9de9815b3982ea5cd4",
     "grade": false,
     "grade_id": "cell-8efc7ccfffa63ee5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Synthesis (3 points)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "Now that you know how to implement the analysis or direct wavelet transform, it is time to get to the synthesis or inverse wavelet transform. In this section, you will first complete the standard filterbank implementation (upsampling followed by filtering), then you will complete the polyphase implementation of the Haar wavelet transform, and finally we will test both implementations against the implementation included in PyWavelets.\n",
    "\n",
    "## 3.A. Filterbank implementation - Synthesis (2 points)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "Now, **for 2 points** complete the function `synthesis` in Python. The parameters are\n",
    "* `coeffs`: a wavelet transform,\n",
    "* `lp`: the low-pass synthesis filter,\n",
    "* `hp`: the high-pass synthesis filter,\n",
    "* `n`: the number of iterations required to reconstruct the original image,\n",
    "\n",
    "and the output is\n",
    "* `image`: the synthesis of an image from its wavelet coefficients.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Hints:</b>\n",
    "    \n",
    "The structure of the `synthesis` function is very similar to the `analysis` one.\n",
    "     \n",
    "For upsampling, you can again take advantage of advanced indexing in NumPy: you create a new array of the right size, and you fill every other of its positions with the image you want to upsample. You can look at the images in [Section 1.A](#1.A.-Boundary-conditions) for an idea on how the upsampling should work. Make sure to verify your ideas on a small, separate example before you move on.\n",
    "    \n",
    "<b>As usual, we do not accept answers that use loops to iterate through images</b>. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53528cd06f1a7ab3b1c07a36844c4a96",
     "grade": false,
     "grade_id": "cell-af03fc46168d85df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on coeffs\n",
    "def synthesis(coeffs, lp, hp, n):\n",
    "    # Get dimensions of the last wavelet transform\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(coeffs.shape) // div\n",
    "    # Declare output\n",
    "    output = np.copy(coeffs)\n",
    "    for i in range(n):\n",
    "        # Extract wavelet coefficients (the smallest transform at first, then \n",
    "        # incorporating more and more coefficients)\n",
    "        wt_iter = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable wt_iter, which is incorporated into\n",
    "        # output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal inverse transfrom\n",
    "        # Split wt_iter into its two horizontal components\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Upsample each component\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Filter each component with the corresponding filter\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Combine the results into one component\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## Vertical inverse transform\n",
    "        # Repeat all the steps above for the vertical components (on the output\n",
    "        # of the inverse horizontal transform)\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Replace synthesis of corresponding iteration\n",
    "        output[0:ny, 0:nx] = wt_iter\n",
    "        # Update dimensions for next scale\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fec047fce20f810ec3b0aed65d3dec44",
     "grade": false,
     "grade_id": "cell-42ea381bd8fa49d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First of all, as a preliminary test on your implementation, run the next cell to reconstruct the image `lowlight`. We will first decompose it using the function `pywt_analysis`, so that we only test your implementation of `synthesis`. We will plot the original and the synthesis. You can inspect them visually and look at the statistics to decide if it is correct.\n",
    "\n",
    "Run the next cell to see this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56a080b2ff30bdde186d388cd1eb2de1",
     "grade": true,
     "grade_id": "cell-b529e17f9d61a32a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Apply synthesis to doisneau_wt_1py (output from analysis()))\n",
    "mer_de_glace_coef = pywt_analysis(mer_de_glace, 4, 'haar')\n",
    "mer_de_glace_rec = synthesis(mer_de_glace_coef, synthesis_lp, synthesis_hp, 4)\n",
    "\n",
    "plt.close('all')\n",
    "viewer([mer_de_glace_rec, mer_de_glace], title=['Synthesis', 'Original'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a68318d73680cfc87508d6143c0b9d09",
     "grade": false,
     "grade_id": "cell-00d036960a110e27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.B Polyphase implementation of the Haar wavelet transform - Synthesis (1.5 points)\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "In this section you will implement a fast version of the inverse Haar wavelet transform based on the polyphase idea. The key insight is again that in the filterbank implementation, many of the computations made in the convolutions are multiplications by $0$. \n",
    "\n",
    "In a polyphase implementation, we save computations by first applying equivalent filters to the different coefficients, and then creating the output signal by upsampling and shifting them differently before adding them up. **For 0.5 point**, which of the following choices corresponds to the synthesis formula for the Haar wavelet transform? Modify `answer` to reflect your choice.\n",
    "\n",
    "1. $ \\begin{bmatrix} y[2k] \\\\ y[2k + 1] \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}  \\begin{bmatrix} x_1[k] \\\\ x_2[k] \\end{bmatrix}\\,$\n",
    "\n",
    "2. $ \\begin{bmatrix} x[2k + 1] \\\\ x[2k] \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & -1 \\\\ 1 & 1 \\end{bmatrix}  \\begin{bmatrix} y_1[k] \\\\ y_2[k] \\end{bmatrix}\\,$\n",
    "\n",
    "3. $ \\begin{bmatrix} x[2k] \\\\ x[2k + 1] \\end{bmatrix} = \\sqrt{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}  \\begin{bmatrix} y_1[k] \\\\ y_2[k] \\end{bmatrix}\\,$\n",
    "\n",
    "4. $ \\begin{bmatrix} x[2k] \\\\ x[2k + 1] \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & -1 \\\\ 1 & 1 \\end{bmatrix}  \\begin{bmatrix} y_1[k] \\\\ y_2[k] \\end{bmatrix}\\,$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a4fd2c4ff2d01a8edfa18fd42407790",
     "grade": false,
     "grade_id": "cell-de0b146217ef61fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a60219afd19450ccc65df3db448a8f7f",
     "grade": true,
     "grade_id": "cell-40704194f29b34e8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if not answer in [1, 2, 3, 4]:\n",
    "    print('WARNING!!\\nChoose one of 1, 2, 3 or 4. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2f04fe2fc33c4488c32211812312c8b",
     "grade": false,
     "grade_id": "cell-e2adf1444ad60000",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Now **for 1 point**,  complete the follwoing function `poly_synthesis(coeffs, n)`. The parameters of the function are\n",
    "\n",
    "* `coeffs`: the coefficients of a wavelet transform, and\n",
    "* `n`: the number of iterations required to reconstruct the original image,\n",
    "\n",
    "and the output is\n",
    "* `image`: the resulting image.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Note:</b> \n",
    "    <ul>\n",
    "    <li>Do not use <code>ndi.convolve1d</code> nor any function from PyWavelets here.</li>\n",
    "    <li>Don't confuse <code>nx</code> and <code>ny</code>, or get tricked by NumPy's copying mechanisms, as we mentioned in <a href=\"#2.C.-Polyphase-implementation-of-the-Haar-wavelet-transform---Analysis-(1-point)\">Section 2.C.</a> to avoid bugs.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce412ee67efd18c5b087d991711a56c6",
     "grade": false,
     "grade_id": "cell-4c589d9ed1b43363",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on img\n",
    "def poly_synthesis(coeffs, n):\n",
    "    # Get information about the transform (size of the last Wavelet Transform)\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(coeffs.shape) // div\n",
    "    # Generate output array to work on\n",
    "    output = np.copy(coeffs)\n",
    "    for i in range(n):\n",
    "        # Extract wavelet coefficients (the smallest transform at first, then \n",
    "        # incorporating more and more coefficients)\n",
    "        wt_iter = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable wt_iter, which is incorporated into\n",
    "        # output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal inverse transfrom\n",
    "        # Split wt_iter into its two horizontal components\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Apply filterbank matrix (calculate even and odd samples)\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## Vertical inverse transform\n",
    "        # Repeat the steps above for the vertical components\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Replace synthesis of corresponding iteration\n",
    "        output[0:ny, 0:nx] = wt_iter\n",
    "        # Update dimensions for next scale\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e07711fa25ffcea2e96c9d3c6fe8a49",
     "grade": false,
     "grade_id": "cell-80f677ce71802cf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell for a quick test on your polyphase implementation of the synthesis part of the Haar wavelet transform. We will test with the image `mer_de_glace`, and use the function `pywt_analysis` for the analysis so that we are only testing your `poly_synthesis` function, not your analysis function. We will plot the original and the synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80e816e711ea946c98ff6cda083d284f",
     "grade": true,
     "grade_id": "cell-bf68ba2149f44cb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get synthesis\n",
    "mer_de_glace_wt_4 = pywt_analysis(mer_de_glace, 4, 'haar')\n",
    "mer_de_glace_rec_4 = poly_synthesis(mer_de_glace_wt_4,  4)\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([mer_de_glace_rec_4, mer_de_glace], title=['Synthesis (n = 4)', 'Original'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36f4cf09358f0538685b7e516ccbe918",
     "grade": false,
     "grade_id": "cell-1f23474e61da22aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.C. Synthesis with PyWavelets\n",
    "[Back to table of contents](#ToC_1_WT)\n",
    "\n",
    "To finish this section, we will show you how to do this step with PyWavelets and provide numerical tests for both your synthesis  implementations. The basic syntax of `pywt.idwt2` is\n",
    "```python\n",
    "image = pywt.idwt2(coeffs, wavelet = 'haar', mode = 'periodization')\n",
    "```\n",
    "\n",
    "The parameters are\n",
    "* `coeffs`: the exact output of `pywt.dwt2`, i.e.,  `(cA, (cV, cH, cD))` (see [Section 2.D.](#2.D.-Analysis-with-PyWavelets-(1-point))),\n",
    "* `wavelet` (a string): which wavelet to use (see the options [here](https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes)). Clearly, to obtain the correct synthesis, you will need to apply the synthesis with the same wavelet you used for the analysis.\n",
    "* `mode`: as explained before, we will use `'periodization'` (which corresponds to 'wrap' in `ndi.convolve1d`),\n",
    "\n",
    "and the output is\n",
    "* `image`: the resulting image.\n",
    "\n",
    "In the next cell we will provide the function `pywt_synthesis(img, n, wavelet)`, which will perform $n$ iterations of the inverse wavelet transform. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b> To be consistent with the course format, and in a similar way as we did in the function <code>pywt_analysis</code>, the function <code>pywt_synthesis</code> will take as input the coefficients arranged in an <i>image of the same size as the original</i>, i.e., it will be compatible with the output from one of the analysis functions you implemented. We will take care of splitting the image in its coefficients inside the function.   \n",
    "</div> \n",
    "\n",
    "Run the next cell to declare this function and apply it to the image `lowlight` for $n = 1$, and $n = 4$.  Explore the results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c92e1adb82ab463066630e6600964fa",
     "grade": false,
     "grade_id": "cell-7158f3e6e87376e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on img\n",
    "def pywt_synthesis(img, n, wavelet):\n",
    "    # Get information about the transform (size of the last wavelet transform)\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(img.shape) // div\n",
    "    # Generate output array to work on\n",
    "    output = np.copy(img)\n",
    "        \n",
    "    # Iterate through n\n",
    "    for i in range(n):\n",
    "        # Extract coefficients\n",
    "        cA = output[0:ny//2, 0:nx//2]\n",
    "        cH = output[0:ny//2, nx//2:nx]\n",
    "        cV = output[ny//2:ny, 0:nx//2]\n",
    "        cD = output[ny//2:ny, nx//2:nx]\n",
    "        # Apply inverse transform\n",
    "        sub = pywt.idwt2((cA, (cV, cH, cD)), mode = 'periodization', wavelet = wavelet)\n",
    "        # Replace inverse transform in image\n",
    "        output[0:ny, 0:nx] = sub\n",
    "        # Update dimensions\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply the python analysis and color-map\n",
    "lowlight_wt_1 = pywt_analysis(lowlight, 1, 'haar')\n",
    "lowlight_rec_1 = pywt_synthesis(lowlight_wt_1, 1, 'haar')\n",
    "lowlight_wt_4 = pywt_analysis(lowlight, 4, 'haar')\n",
    "lowlight_rec_4 = pywt_synthesis(lowlight_wt_4, 4, 'haar')\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "title_list = [\"Original\", \"Reconstruction (n=1)\", \"Reconstruction (n=4)\"]\n",
    "view = viewer([lowlight_rec_1, lowlight_rec_4, lowlight], title=title_list, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b376907ef889253b91a777af1457ee95",
     "grade": false,
     "grade_id": "cell-0214a158dcd4cc7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! You are pretty much done with this first notebook of the lab. Now that we have all the tools, you will get the final test for both of your implementations, an element-wise comparison of the output from `synthesis`, `poly_synthesis` and `pywt_synthesis` up to the $10^{th}$ decimal with $n = 3$. Of course, the analysis will be done using `pywt_analysis`, so that we only test the synthesis, and not the analysis. Moreover, the filterbank implementation will also be tested with the Daubechies 2 wavelet (DB2), so that in case of mistakes you can see whether your mistake is in the filters or in the synthesis functions. If the following cell runs without any error, congratulations!\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note:</b> If there is any mistake, the next cell will also show you where the results are wrong. We will use the tool <i>compare</i> of IPLabImageViewer. Look for the red areas in the images to get a hint of where you might have gone wrong  (these areas are where your implementation and PyWavelets' differ). Note that you can activate the comparison again after changing images by clicking on <code>Options</code> $\\rightarrow$ <code>Compare</code>.\n",
    "</div>\n",
    "\n",
    "If your implementations are correct, we will calculate the *signal-to-noise ratio (SNR)* (in $\\mathrm{dB}$) of the synthesis with respect to the original and include it in the title. This metric measures the ratio of the power of a signal to the power of the noise (or error). The power of the signal is measured from the original image (for example, $x[l,k]$), and the noise can be measured from the difference between the original image and the reconstruction (for example, $\\hat{x}[l,k]$). Therefore, the SNR is computed using the following expression\n",
    "\n",
    "$$\\operatorname{SNR}(x, \\hat{x}) = \\frac{\\operatorname{P}_{signal}}{\\operatorname{P}_{noise}} = \\frac{ \\sum_{l,k} x^2[l,k]}{\\sum_{l,k} (x[l,k] - \\hat{x}[l,k])^2} \\mbox{, and } \\operatorname{SNR}(x, \\hat{x})~[\\mathrm{dB}] = 10 \\log_{10}\\left(\\operatorname{SNR}(x, \\hat{x})\\right)\\,,$$\n",
    "\n",
    "where the summation is done over all pixels. In $\\mathrm{dB}$, a value of $0$ means that we have more signal than noise, and the higher the SNR the better. Pay attention to it!\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "\n",
    "<b>Note:</b> As usual, the fact that this cell runs does not guarantee the points.\n",
    "</div>\n",
    "\n",
    "Run the next cell to apply the tests with the image `lighthouse`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d61817bdbce17d94171cfdfd85d2a9c",
     "grade": false,
     "grade_id": "cell-ec043f50c41e150c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define n\n",
    "n = 3\n",
    "\n",
    "## Checking results for Haar wavelet transform\n",
    "# Get Haar wavelet transform\n",
    "lighthouse_wt = pywt_analysis(lighthouse, n, 'haar')\n",
    "\n",
    "# Get the three reconstructions (PyWavelets, generic filterbank, polyphase)\n",
    "lighthouse_rec_pywt = pywt_synthesis(lighthouse_wt, n, 'haar')\n",
    "lighthouse_rec_poly = poly_synthesis(lighthouse_wt, n)\n",
    "lighthouse_rec_filt = synthesis(lighthouse_wt, synthesis_lp, synthesis_hp, n)\n",
    "\n",
    "# Close all viewers\n",
    "plt.close('all')\n",
    "\n",
    "# Initialize flag to see if there are problems with the Haar wavelet results\n",
    "error_haar = False; error_haar_filt = False\n",
    "# Check polyphase implementation of Haar wavelet transform\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_poly, lighthouse_rec_pywt, decimal=10)\n",
    "except Exception as e:\n",
    "    print('Your polyphase implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True\n",
    "    viewer([lighthouse_rec_poly, lighthouse_rec_pywt], \n",
    "           title = [\"Polyphase (Haar)\", \"PyWavelets (Ground truth)\"], compare=True, widgets=True)\n",
    "    \n",
    "# Check generic filterbank implementation of Haar wavelet transform     \n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_filt, lighthouse_rec_pywt, decimal=10)\n",
    "except Exception as e:\n",
    "    print('Either your filterbank implementation is not correct, or your Haar filters are not (check the test with \\\n",
    "            DB2 filters to know for sure). Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True; error_haar_filt = True\n",
    "    viewer([lighthouse_rec_filt, lighthouse_rec_pywt], \n",
    "           title = [\"Filterbank (Haar)\", \"PyWavelets (Ground truth)\"], compare=True, widgets=True)\n",
    "    \n",
    "## Checking results for DB2 wavelet transform\n",
    "# Set the coefficients \n",
    "a = (1 + np.sqrt(3))/(4*np.sqrt(2)); b = (3 + np.sqrt(3))/(4*np.sqrt(2))\n",
    "c = (3 - np.sqrt(3))/(4*np.sqrt(2)); d = (1 - np.sqrt(3))/(4*np.sqrt(2))\n",
    "# Define the filters\n",
    "analysis_lp_db2  = np.array([d, c, b, a, 0]);  analysis_hp_db2 = np.array([-a, b, -c, d, 0])\n",
    "synthesis_lp_db2 = np.array([0, a, b, c, d]); synthesis_hp_db2 = np.array([0, d, -c, b, -a])\n",
    "\n",
    "# Get DB2 wavelet transform\n",
    "lighthouse_wt = pywt_analysis(lighthouse, n, 'db2')\n",
    "\n",
    "# Get the two reconstructions (PyWavelets, generic filterbank)\n",
    "lighthouse_rec_filt_db2 = synthesis(lighthouse_wt, synthesis_lp_db2, synthesis_hp_db2, n)\n",
    "lighthouse_rec_pywt_db2 = pywt_synthesis(lighthouse_wt, n, 'db2')\n",
    "\n",
    "# Initialize flag to see if there are problems with the DB2 wavelet results\n",
    "error_db = False\n",
    "# Check generic filterbank implementation of DB2 wavelet transform\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_filt_db2, lighthouse_rec_pywt_db2, decimal=10)\n",
    "    if error_haar_filt:\n",
    "        print('Your filterbank implementation is correct, but you should check your Haar filters.')\n",
    "except Exception as e:\n",
    "    print('Your filterbank implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_db = True\n",
    "    viewer([lighthouse_rec_filt_db2, lighthouse_rec_pywt_db2], \n",
    "           title = [\"Filterbank (DB2)\", \"PyWavelets (Ground truth)\"], compare=True, widgets=True)\n",
    "\n",
    "# If everything is correct, we want the SNR in the title of each image\n",
    "def snr_db(orig, img):\n",
    "    snr = 10*np.log10(np.sum(orig**2)/np.sum((img - orig)**2))\n",
    "    return snr \n",
    "\n",
    "if not(error_db or error_haar):\n",
    "    print('Congratulations! You are as good as the most accepted wavelet library in Python. Now, let\\'s look \\\n",
    "at the quality of the synthesis for the different methods using the SNR.')\n",
    "    image_list = [lighthouse_rec_pywt, \n",
    "                  lighthouse_rec_poly, \n",
    "                  lighthouse_rec_filt, \n",
    "                  lighthouse_rec_pywt_db2,\n",
    "                  lighthouse_rec_filt_db2,\n",
    "                  lighthouse]\n",
    "\n",
    "    titles = [f'PyWT (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_pywt), decimals=2)} dB)', \n",
    "              f'Polyphase (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_poly), decimals=2)} dB)',\n",
    "              f'Filterbank (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_filt), decimals=2)} dB)',\n",
    "              f'PyWT (DB2, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_filt_db2), decimals=2)}) dB', \n",
    "              f'Filterbank (DB2, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_pywt_db2), decimals=2)} dB)',\n",
    "              'Original']\n",
    "\n",
    "    plt.close('all')\n",
    "    wavelet_viewer = viewer(image_list, title=titles, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f3755e938b87a86c268987488c58aa9",
     "grade": false,
     "grade_id": "cell-4d73d2a7a9c5c5d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Did you reflect on the values of the SNR? As an experiment, we will start eliminating a fixed percentage of the smallest elements of the wavelet coefficients. As you will see later in the course, each image transform has a different curve of the *SNR vs the percentage of coefficients kept* for every type of image.    \n",
    "\n",
    "We will plot this curve for your functions and the PyWavelets implementation. If your implementation is completely correct, the curves should be almost indistinguishable. Look at the comments in the next cell for a thorough explanation. We will use the image `doisneau` and $n = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7b845cbd2e32d2455e91c80c7937504",
     "grade": false,
     "grade_id": "cell-0c1d0c312c2cda58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define compression rates to test\n",
    "compression_rates = [0.1, 0.3, 0.5,  1, 3, 5, 10, 20, 30, 50, 60]\n",
    "\n",
    "# Define compression function \n",
    "def compress(img, per):\n",
    "    output = np.copy(img)\n",
    "    # Get the value of  the threshold\n",
    "    T = np.percentile(np.abs(output), 100-per)\n",
    "    # Set to zero all the pixels below the threshold\n",
    "    output[np.abs(output) < T] = 0\n",
    "    return output\n",
    "\n",
    "# Initialize varible to store SNRs\n",
    "snrs_poly = np.empty_like(compression_rates)\n",
    "snrs_filt = np.empty_like(compression_rates)\n",
    "snrs_pywt = np.empty_like(compression_rates)\n",
    "# Pre-compute wavelet transforms\n",
    "wt_poly = poly_analysis(doisneau, 1)\n",
    "wt_filt = analysis(doisneau, analysis_lp, analysis_hp, 1)\n",
    "wt_pywt = pywt_analysis(doisneau, 1, 'haar')\n",
    "# Iterate through compression rates\n",
    "for idx, per in enumerate(compression_rates):\n",
    "    # compress and reconstruct with polyphase formulation. Get SNR\n",
    "    comp_poly = compress(wt_poly, per)\n",
    "    rec_poly = poly_synthesis(comp_poly,1)\n",
    "    snrs_poly[idx] = snr_db(doisneau, rec_poly)\n",
    "    # compress and reconstruct with filterbanks. Get SNR\n",
    "    comp_filt = compress(wt_filt, per)\n",
    "    rec_filt = synthesis(comp_filt, synthesis_lp, synthesis_hp, 1)\n",
    "    snrs_filt[idx] = snr_db(doisneau, rec_filt)\n",
    "    # compress and reconstruct with pywt. Get SNR\n",
    "    comp_pywt = compress(wt_pywt, per)\n",
    "    rec_pywt = pywt_synthesis(comp_pywt, 1, 'haar')\n",
    "    snrs_pywt[idx] = snr_db(doisneau, rec_pywt)\n",
    "\n",
    "# Close existing figures and initialize a new one\n",
    "plt.close('all')\n",
    "plt.figure(figsize=[10, 7])\n",
    "ax = plt.gca()\n",
    "# Declare lines. Store in variable p to add legends later\n",
    "p = plt.plot(compression_rates, snrs_poly, 'r-o', \n",
    "             compression_rates, snrs_filt, 'b--o', \n",
    "             compression_rates, snrs_pywt, 'g:o')\n",
    "\n",
    "# Make log scale\n",
    "plt.xscale('log')\n",
    "plt.xticks([0.1, 0.5, 1, 5, 10, 50, 100])\n",
    "plt.xlabel('% of coefficients kept')\n",
    "plt.ylabel('SNR [dB]')\n",
    "plt.title('SNR [dB] vs % of coefficients kept')\n",
    "ax.grid(which = 'both')\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend(p, ['Polyphase', 'Filterbank', 'PyWT (Ground truth)'], fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98d1c4c7412e6998a14b04fa0508563",
     "grade": false,
     "grade_id": "cell-bc4dedb3070c5b3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note:</b> If you really enjoyed this notebook, you love wavelets and want to keep exploring the topic, use the following cell to play around! We have included a widget with several functionalities (visualizing both the wavelet transform and the reconstruction with different colormaps, values of $n$, and different wavelet families), all using PyWavelets. Feel free to change or add any code! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "n_slider = widgets.IntSlider(value=1, min=0, max=4, step=1, description='n') \n",
    "wt_menu = widgets.Dropdown(options=['haar', 'db2', 'db10', 'bior1.3', 'bior6.8', 'rbio1.3', 'dmey'], value='haar', description='WT:')\n",
    "mapping_menu = widgets.Dropdown(options=['None', 'Normalize Std Dev', 'Non-Uniform Mapping'], value='None', description='Mapping:')\n",
    "mode_menu = widgets.Dropdown(options=['WT', 'iWT'], value='WT', description='Mode')\n",
    "button = widgets.Button(description='Apply')\n",
    "\n",
    "def wavelet_callback(img):\n",
    "    n = n_slider.value\n",
    "    wt = wt_menu.value\n",
    "    output = pywt_analysis(img, n, wt)\n",
    "    if mode_menu.value == 'WT':\n",
    "        if mapping_menu.value == 'None':\n",
    "            output = map_color(output, n=n, color_map=np.array)\n",
    "        elif mapping_menu.value == 'Normalize Std Dev':\n",
    "            output = map_color(output, n=n, color_map=norm_std_map)\n",
    "        else:\n",
    "            output = map_color(output, n=n, color_map=non_uniform_map)\n",
    "    else:\n",
    "        output = pywt_synthesis(output, n, wt)\n",
    "    return output\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "wavelet_viewer = viewer(lighthouse, title=\"WT Analysis\", \n",
    "                        new_widgets=[n_slider, wt_menu, mapping_menu, mode_menu, button], \n",
    "                        callbacks=[wavelet_callback], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ecb90b3935584682214cf032af281f7",
     "grade": false,
     "grade_id": "cell-6b7bfa65608a203d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<p><b>Congratulations on finishing the first part of the Wavelets lab!</b></p>\n",
    "<p>\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/mod/assign/view.php?id=1148687\">Moodle</a>, in a zip file with other notebooks of this lab.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "* Keep the name of the notebook as: *1_Wavelet_Transform.ipynb*,\n",
    "* Name the zip file: *Wavelets_lab.zip*.\n",
    "<!--\n",
    "<div class=\"alert alert-danger\">\n",
    "<h4>Feedback</h4>\n",
    "    <p style=\"margin:4px;\">\n",
    "    This is the first edition of the image-processing laboratories using Jupyter Notebooks running on Noto. Do not leave before giving us your <a href=\"https://moodle.epfl.ch/mod/feedback/view.php?id=1148686\">feedback here!</a></p>\n",
    "</div>\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "sos": {
   "kernels": [
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#c8e1ae",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0
   },
   "version": "0.21.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375.152px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
