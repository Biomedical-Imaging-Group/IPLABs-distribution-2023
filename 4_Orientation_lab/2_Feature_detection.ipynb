{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74afbd01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f37358716b2ed132ce13d938ba14513e",
     "grade": false,
     "grade_id": "cell-ac5824b0101cdd03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing II</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=463\">MICRO-512</a>) taught by Dr. D. Sage, Dr. M. Liebling, Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL <mark>2024</mark>.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay L\u00e4chler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguer\u00f3n Ar\u00e1mburu</a>,\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>.\n",
    "     \n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 4.2: Feature detection</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: <mark>Thursday February 22, 2024</mark></p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <span style=\"color:red\"><mark>Monday March 4, 2024</mark></span> (before 11:59PM) on <a href=\"https://moodle.epfl.ch/course/view.php?id=463\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Lab session</b>: <mark>Thursday 29 February in CM 1 2</mark></p>    \n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapter 6</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850d879",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Student Name: \n",
    "### SCIPER: \n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525a43a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c13f19e9a688d28b42b6e9e98359088",
     "grade": true,
     "grade_id": "cell-c88e573756df7200",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594eb2e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "921f1832f5101a1fa7ceae3abb481fa9",
     "grade": false,
     "grade_id": "cell-865b247cc683f8f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import Python libraries we will use throughout the lab, as well as the `ImageViewer` class, created specifically for this course, which provides interactive image visualization based on the `ipywidgets` library:\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org/3.2.2/api/_as_gen/matplotlib.pyplot.html), to display images,\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive,\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays,\n",
    "* [`cv2`](https://docs.opencv.org/2.4/index.html), for image processing tasks.\n",
    "\n",
    "We will then load the `ImageViewer` class (see the documentation [here](https://github.com/Biomedical-Imaging-Group/interactive-kit/wiki/Image-Viewer) or run the Python command `help(viewer)` after loading the class).\n",
    "\n",
    "Finally, we load the images you will use in the exercise to test your functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d60ddd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "854481e82f6c6c6ecf65526283ee73e6",
     "grade": false,
     "grade_id": "cell-a2ebd99c0ef22729",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import standard required packages for this exercise\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "from interactive_kit import imviewer as viewer \n",
    "\n",
    "# Load images to be used in this exercise\n",
    "img_mouse     = cv.imread('images/mouse.tif',     cv.IMREAD_UNCHANGED)\n",
    "img_fundus    = cv.imread('images/fundus.tif',    cv.IMREAD_UNCHANGED)\n",
    "img_eiffel    = cv.imread('images/eiffel.tif',    cv.IMREAD_UNCHANGED)\n",
    "img_bikesgray = cv.imread('images/bikesgray.tif', cv.IMREAD_UNCHANGED)\n",
    "img_covid     = cv.imread('images/covid.tif',     cv.IMREAD_UNCHANGED)\n",
    "img_nft       = cv.imread('images/nft.tif',       cv.IMREAD_UNCHANGED)\n",
    "img_onion     = cv.imread('images/onion.tif',     cv.IMREAD_UNCHANGED)\n",
    "img_grayfig   = cv.imread('images/grayfig.tif',   cv.IMREAD_UNCHANGED)\n",
    "img_object    = cv.imread('images/objects.tif',   cv.IMREAD_UNCHANGED)\n",
    "\n",
    "# Create some test images\n",
    "dim = 200\n",
    "szx = slice(int(0.475*dim), int(0.525*dim), None)\n",
    "img_noise200 = 50.0 * np.random.rand(dim, dim) \n",
    "\n",
    "x, y = np.meshgrid(np.arange(-dim//2, dim//2), np.arange(-dim//2, dim//2))\n",
    "img_circle200 = img_noise200 + (x**2 + y **2 <= (0.35*dim)**2)*255\n",
    "\n",
    "img_cross200 = img_noise200 + np.zeros((dim, dim), dtype=np.float64)\n",
    "img_cross200[szx,:] += 255.0\n",
    "img_cross200[:,szx] += 255.0\n",
    "img_cross200[szx,szx] -= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9439dd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "279b275ddc6036c2fa913bdb54075749",
     "grade": false,
     "grade_id": "cell-8ea8caca15580ea5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We also import the JavaScript `ImageAccess` class as `Image`. You can find the documentation of the class [here](https://biomedical-imaging-group.github.io/image-access/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f612547",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19bc115aaa9e56662d9c61d1cd803c0e",
     "grade": true,
     "grade_id": "cell-9dcec9edd5e6769b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// import image-access as Image\n",
    "var Image = require('image-access')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62691201-599d-4f4c-ba40-e33274c85828",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ec44effbebcc3d94c37e7a5d9558a2a",
     "grade": false,
     "grade_id": "cell-7f59c9184c96085a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Feature detection (17 points)\n",
    "\n",
    "In this lab we will compare different use cases of edge detection and ridge detection, presented in the Appendix of Chapter 6. These algorithms play an essential role in capturing key features and properties from an image when deep learning is not viable or simply not the easier solution. We will first implement the key parts of each to grasp how they work and then explore some of the tricks that OpenCV has reserved for us behind the scene.\n",
    "\n",
    "As customary for edge detection we will work with greyscale images in this lab. This is to minimize the computational cost and simplify the complexity of edge detection algorithms. \n",
    "\n",
    "## <a id=\"ToC_2_Feature_detection\"></a>Table of contents\n",
    "1. [Original Canny edge detector](#1.-Original-Canny-edge-detector-(17-points)) \n",
    "    1. [Noise reduction](#1.A.-Noise-reduction-(1-points)) **(1 points)**    \n",
    "    2. [Magnitude and phase of the gradient](#1.B.-Magnitude-and-phase-of-the-gradient-(3-points)) **(3 points)** \n",
    "    3. [Non-maximum suppression](#1.C.-Non-maximum-suppression-(3-points)) **(3 points)** \n",
    "    4. [Hysteresis thresholding](#1.D.-Hysteresis-thresholding-(4-points)) **(5 points)**\n",
    "    5. [Comparison with OpenCV](#1.E.-Comparison-with-OpenCV)\n",
    "    6. [The switch to OpenCV](#1.F.-The-switch-to-OpenCV-(2-points)) **(2 points)**\n",
    "2. [Original ridge detector](#2.-Original-ridge-detector-(3-points)) \n",
    "    1. [Motivation](#2.A.-Motivation)\n",
    "    2. [Implementation](#2.B.-Implementation-(3-points)) **(3 points)**\n",
    "\n",
    "### Visualize images\n",
    "First of all, run the cell below to get familiar with the images we will be using. Remember you can use the `Widgets` to cycle through the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc23f8b-82ed-438a-bcfb-6e8c62584324",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09d4c084b546eaa7a1e10a9bc437ce85",
     "grade": false,
     "grade_id": "cell-3453ad9728b4c751",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Display all the images we will use in this lab\n",
    "images_list = [img_object, img_mouse, img_fundus, img_eiffel, img_bikesgray, img_covid, img_nft, img_onion, img_cross200, img_circle200, img_grayfig]\n",
    "plt.close('all')\n",
    "imgs_viewer = viewer(images_list, widgets=True, use_slider=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca101fe8-ccf4-4163-ad6d-30f1b17655e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f38dae52d028b1bcdd23a42e3b84fa1",
     "grade": false,
     "grade_id": "cell-d55ee1f16cfb6a5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 1. Original Canny edge detector (13 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "Over time, detecting edges has proven to be a great way to capture important features from images. They could be indicative of discontinuities in the environment, depth or brightness changes, varying material properties etc. There are drawbacks to the method, for example, a shadow casted on a flat surface would result in an edge being detected... Nevertheless, the commonly used Canny edge detector remains a fundamental tool in image processing.\n",
    "\n",
    "The algorithm consists of four parts that we will now cover in detail.\n",
    "1. Noise reduction\n",
    "2. Gradient magnitude and phase calculation \n",
    "3. Non-maximum suppression\n",
    "4. Hysteresis thresholding\n",
    "\n",
    "<center><img src=\"images/edge_detector_schematic.png\" width=\"800\"/></center>\n",
    "\n",
    "As it turns out we have in our lab a copy of John F. Canny's thesis.\n",
    "\n",
    "<center><img src=\"images/thebook.jpg\" width=\"800\"/></center>\n",
    "\n",
    "In this first part we will be using the following two synthetic images `img_cross200` and `img_circle200`. Run the next cell and observe how the noise could make it tricky to distinguish the shapes' edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d927f-73ec-465f-90c4-fd964f187492",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd4b06b31039348da1543e5f81745873",
     "grade": false,
     "grade_id": "cell-30ca5a747d8ec146",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Display the two images\n",
    "image_list = [img_cross200, img_circle200]\n",
    "title_list = ['Cross200 Original', 'Circle200 Original']\n",
    "plt.close('all')\n",
    "view1 = viewer(image_list, title=title_list, subplots=(1,2), joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd51fb-51df-4cc4-a1b6-0a97d319bd5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27a77b12b0a044cc0d850efe7d4a3a82",
     "grade": false,
     "grade_id": "cell-32e4b58c2e16bd85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.A. Noise reduction (1 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "In this step, the goal is to mask any undesired features of lesser importance to our image analysis. Imagine an older low quality image or one that has been taken through a dirty window - you don't want to see that mess, do you? From a numerical point of view it is also useful when dealing with synthetic images, that do not have smooth transitions, whose uniformity could be hurtful to the next steps of the algorithm.\n",
    "\n",
    "For this step we will use the gaussian filter you implemented in the warm up notebook of this lab. We will spare you the details this time and make use of OpenCV directly. In the next cell, **for 1 point**, complete the `smooth_gaussian` function so as to obtain a **blurred image** using [`cv.GaussianBlur`](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1). If you are unsure about its input parameters, go check the documentation. We will provide `sigma`, so make sure to set the kernel size `ksize` to be computed from sigma, and set the `borderType` parameter of `cv.GaussianBlur` to the `borderType` input parameter. Use the following cell to check your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94ca1a",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5fa8b3400391c9e32f7d39372850ff7",
     "grade": false,
     "grade_id": "cell-e909c7bdd8b98791",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that implements a Gaussian smoothing using cv.GaussianBlur\n",
    "def smooth_gaussian(image, sigma=3, borderType=cv.BORDER_REFLECT):\n",
    "    # convert image to high precision floating point values\n",
    "    image = np.float64(image)\n",
    "    blurred_image = np.zeros(image.shape)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834b6f-2e7f-4baa-a6b9-bae8dda12073",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "129164992039ab0671d34f0c37261446",
     "grade": false,
     "grade_id": "cell-709bd2ea81aadbed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Apply the Gaussian blurring to the two test images\n",
    "img_cross200_blur = smooth_gaussian(img_cross200)\n",
    "img_circle200_blur = smooth_gaussian(img_circle200)\n",
    "# Display the resulting images together with their originals\n",
    "image_list = [img_cross200, img_circle200, img_cross200_blur, img_circle200_blur]\n",
    "title_list = ['Cross200 Original', 'Circle200 Original', 'Cross200 Blurred', 'Circle200 Blurred']\n",
    "plt.close('all')\n",
    "view1a = viewer(image_list, title=title_list, subplots=(2,2), joint_zoom=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45fdbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dcd94a62c692b8e85b361148211478f",
     "grade": false,
     "grade_id": "cell-ff45c5b198c73662",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform a quick sanity check. We should have a lower variance in the blurred image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6632ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ebe269e56d29f9eeb31c0c76470dc90",
     "grade": true,
     "grade_id": "cell-955f62f788a39d37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Basic sanity check\n",
    "# Lower variance / standard deviation in the blurred image\n",
    "if np.std(img_cross200) < np.std(img_cross200_blur):\n",
    "    print('WARNING!\\nThis does not seem right, make sure you called the function using the correct parameters.')\n",
    "else :\n",
    "    print('Congratulations! Your blurring passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471456e-2106-45c0-b1ce-66512d169332",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0c4e009d176af49b498e7c27f16bb99",
     "grade": false,
     "grade_id": "cell-7be921fa2fefd708",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.B. Magnitude and phase of the gradient (3 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "In this step, the goal is to extract the edge features from our image. An edge is characterized by an abrupt change in the image magnitude and the next steps of the algorithm care about the direction of the gradient which we call phase. \n",
    "\n",
    "For this step we will use the OpenCV Sobel filter [`cv.Sobel`](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d) to compute our gradients. If you are unsure about its input parameters, go check the documentation. In the next cell, **for 3 points**, complete the `compute_gradient_features` function so as to compute the **magnitude, phase and normalized gradients along x and y**. We will provide `ksize` and `borderType` set by default to `BORDER_REFLECT`. Use the following cell to check your output.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Hints:</b> \n",
    "<ul>\n",
    "    <li>Take a moment to go thoroughly through the documentation! It will make your life much easier.</li>\n",
    "    <li><code>cv.Sobel</code>: set <code>ddepth=cv.CV_64F</code> since the gradient can be a negative floating point number.</li>\n",
    "    <li>Definitions, where $\\partial_{x,y} I(x,y) = \\frac{\\partial I(x,y)}{\\partial x,y}$ and $I(x,y)$ being the input image:\n",
    "    <ul>\n",
    "        <li>magnitude: $|| \\nabla I(x,y)|| = \\sqrt{(\\partial_{x} I)^2 + (\\partial_{y} I)^2}$</li> \n",
    "        <li>phase: $ \\angle\\big( \\nabla I(x,y)\\big) = \\arctan\\big(\\partial_{y} I / \\partial_{x} I\\big)$.</li>\n",
    "        <li>normalization: $\\partial_{x,y} I_{\\scriptsize{\\mbox{norm}}}(x,y) = \\frac{\\partial_{x,y} I(x,y)}{|| \\nabla I(x,y)||}$.</li>\n",
    "    </ul>\n",
    "    <li><code><a href=\"https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html\" style=\"color:black\">np.arctan2</a></code>: could help you get the correct angle in all four quadrants.</li>\n",
    "    <li>When normalizing the $x$ and $y$ components of the gradient, prevent any division by zero.</li>\n",
    "    <li>To ensure that you set the correct input parameter in a function call always specify the name of the input parameter you want to set.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2419f",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9ee6950910e2069db6d2c3ca4fdbe44",
     "grade": false,
     "grade_id": "cell-bca0b4457ba0f79c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that computes the magnitude, phase, as well as the x- and y-components of the gradient\n",
    "def compute_gradient_features(image, ksize=3, borderType=cv.BORDER_REFLECT):\n",
    "    magnitude = np.zeros(image.shape)\n",
    "    phase = np.zeros(image.shape)\n",
    "    norm_gradX = np.zeros(image.shape)\n",
    "    norm_gradY = np.zeros(image.shape)\n",
    "    \n",
    "    # Calculate the x and y components of the gradient cv.Sobel\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Calculate the magnitude and phase of the gradient\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Normalize the x and y components of the gradient by the magnitude of the gradient\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return magnitude, phase, norm_gradX, norm_gradY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989706b7-a14b-4d87-a3a6-2e1529c358d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e74ebd6407599a2d1720383820c1c885",
     "grade": false,
     "grade_id": "cell-e16aa9562b94e447",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Compute the gradient features on the cross and circle images\n",
    "img_cross200_magphase = np.array(compute_gradient_features(img_cross200_blur))\n",
    "img_circle200_magphase = np.array(compute_gradient_features(img_circle200_blur))\n",
    "# Prepare image and title lists for the visualization\n",
    "image_list = [img_cross200_blur, img_circle200_blur, img_cross200_magphase[0], img_circle200_magphase[0], \n",
    "                                                     img_cross200_magphase[1], img_circle200_magphase[1],\n",
    "                                                     img_cross200_magphase[2], img_circle200_magphase[2],\n",
    "                                                     img_cross200_magphase[3], img_circle200_magphase[3]]\n",
    "title_list = ['Cross200 Blurred', 'Circle200 Blurred', 'Cross200 Magnitude',  'Circle200 Magnitude',\n",
    "                                                       'Cross200 Phase',      'Circle200 Phase',\n",
    "                                                       'Cross200 Gradient X', 'Circle200 Gradient X',\n",
    "                                                       'Cross200 Gradient Y', 'Circle200 Gradient Y']\n",
    "plt.close('all')\n",
    "view1b = viewer(image_list, title=title_list, subplots=(5,2), joint_zoom=True, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb33d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3e9711ad0d9bf88d21109931da85d4e",
     "grade": false,
     "grade_id": "cell-bae94d013e489eb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform a quick sanity check. The magnitude values should be positive and only the edges of the shapes should have high intensity values. The phase values should span the entire $[-\\pi, \\pi]$ range. The normalised x- and y-components of the gradient should be in the range $[-1,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090b821",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba0888578f1411631f946b61989e86c7",
     "grade": true,
     "grade_id": "cell-f94dc1aa42cabb7e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Basic sanity checks\n",
    "error_check = False\n",
    "# Magnitude values expected to be positive\n",
    "if not (np.all(img_cross200_magphase[0] >= 0) and np.all(img_circle200_magphase[0] >= 0)) :\n",
    "    print('WARNING!\\nYour magnitude values should all be positive.')\n",
    "    error_check = True\n",
    "\n",
    "# The inner cross should now look darker\n",
    "if not (np.mean(img_cross200_magphase[0][dim//2,:] + img_cross200_magphase[0][:,dim//2]) < 0.25*np.mean(img_cross200[dim//2,:] + img_cross200[:,dim//2]) and \\\n",
    "        np.mean(img_circle200_magphase[0][dim//2,:] + img_circle200_magphase[0][:,dim//2]) < 0.25*np.mean(img_circle200[dim//2,:] + img_circle200[:,dim//2])):\n",
    "    print('WARNING!\\nOnly the edges of the shapes should have high intensity values, the inside should be dark.')\n",
    "    error_check = True\n",
    "\n",
    "# Phase values span the [-pi, pi] range\n",
    "if np.abs(np.max(img_circle200_magphase[1]) - np.pi) > 1e-3 or np.abs(np.min(img_circle200_magphase[1]) + np.pi) > 1e-3 or\\\n",
    "   np.abs(np.max(img_cross200_magphase[1]) - np.pi) > 1e-3 or np.abs(np.min(img_cross200_magphase[1]) + np.pi) > 1e-3:\n",
    "    print('WARNING!\\nYour phase values should span the range [-pi, pi].')\n",
    "    error_check = True\n",
    "    \n",
    "# Normalised gradient values are within [-1, 1]\n",
    "if np.abs(np.max(img_circle200_magphase[2]) - 1) > 1e-3 or np.abs(np.min(img_circle200_magphase[2]) + 1) > 1e-3 or\\\n",
    "   np.abs(np.max(img_circle200_magphase[3]) - 1) > 1e-3 or np.abs(np.min(img_circle200_magphase[3]) + 1) > 1e-3:\n",
    "    print('WARNING!\\nYour normalised x- and y-components of the gradient should be in the range [-1, 1].') \n",
    "    error_check = True\n",
    "    \n",
    "if error_check:\n",
    "    print('Make use of the above visualization to locate your errors')\n",
    "else :\n",
    "    print('Congratulations! Your gradient features passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1efac-b5a5-4690-b343-35a39851801f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa38e849260187ca903127da28aada43",
     "grade": false,
     "grade_id": "cell-35caa089efdbe0ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.C. Non-maximum suppression (3 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "In this step, the goal is to filter our magnitude image and eliminate the pixels that do not represent a peak along the direction of the gradient, akin to determining a zero crossing of the second order (directional) derivative.\n",
    "\n",
    "For this step we will ask you to **code in JavaScript** to get a lower level understanding of how this works. In the second next cell, **for 2 points**, your task is to implement `applyNonMaximumSuppressionInterpolation` where you will examine whether the **gradient magnitude** pixel value is **strictly greater** than its two neighbours **along the gradient direction**, in which case we want to keep it, otherwise we will discard it.\n",
    "\n",
    "The function and parameters are given as follows:\n",
    "\n",
    "<code>applyNonMaximumSuppressionInterpolation(magnitude, norm_grad_x, norm_grad_y)</code>\n",
    "<ul>\n",
    "    <ul>\n",
    "        <li><code>magnitude</code> is the gradient magnitude</li>\n",
    "        <li><code>norm_grad_x</code> and <code>norm_grad_y</code> are the normalised x- and y-components of the gradient </li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "The output shall be an image where all **non-maximum pixels are suppressed** (set to zero).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Hints:</b> \n",
    "<ul>\n",
    "    <li>The gradient direction is perpendicular to the edges and is given by the vector $\\boldsymbol{u} = \\nabla I(\\boldsymbol{x})$, with $||\\boldsymbol{u}|| = 1$.</li>\n",
    "    <li>The mathematical expression for NMS (non-maximum suppression) is to keep only pixels for which $|| \\nabla I(\\boldsymbol{x})|| > || \\nabla I(\\boldsymbol{x} \\pm \\boldsymbol{u})||$</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Since the location $\\boldsymbol{x} \\pm \\boldsymbol{u}$ that we want to check will not always correspond to an exact integer value, we need to interpolate the pixel values for the given location. In the next cell we provide you the function `getInterpolatedPixel(image, x, y)` that returns the in-between pixel values determined using [bilinear interpolation](https://en.wikipedia.org/wiki/Bilinear_interpolation). You will cover interpolation in a future lab, in much greater detail.\n",
    "\n",
    "The function `getInterpolatedPixel(image, x, y)` takes as input parameters:\n",
    "* `image` : The image from which we want to get an interpolated pixel value,\n",
    "* `x` : The x location, which we want to interpolate and\n",
    "* `y` : The y location, which we want to interpolate.\n",
    "\n",
    "And returns the interpolated pixel value of `image` at (`x`, `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c05d42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e055e99a5455210f01046a2e4457901b",
     "grade": false,
     "grade_id": "cell-65ff7bb17845b892",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// Simple linear interpolation function\n",
    "function getInterpolatedPixel(image, x, y){\n",
    "    return (x - parseInt(x)) * (image.getPixel(parseInt(x)+1, parseInt(y)+1) * (y - parseInt(y)) - image.getPixel(parseInt(x)+1, parseInt(y)) * ((y - parseInt(y)) - 1.0)) - ((x - parseInt(x)) - 1.0) * (image.getPixel(parseInt(x), parseInt(y)+1) * (y - parseInt(y)) - image.getPixel(parseInt(x), parseInt(y)) * ((y - parseInt(y)) - 1.0));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9ba53-fe0b-4b8d-ac25-03c8cce8f842",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cbd3012fbd76c5aa0382bbdaef5ad88",
     "grade": false,
     "grade_id": "cell-6797aec0658a0b2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note:** You don't need to worry about the boundary conditions here, because `.getPixel` already applies mirror boundary conditions by default. You will see later that OpenCV deals with them differently and what effects that has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54ccf4-ab35-4ae5-999e-d86ebda3b60c",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68753e89046cbb9625385c2d6d147eac",
     "grade": false,
     "grade_id": "cell-62ae887f1995543c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// Function that applies non-maximum suppresion using bilinear interpolation\n",
    "function applyNonMaximumSuppressionInterpolation(magnitude, norm_grad_x, norm_grad_y){\n",
    "    var nms = new Image(magnitude.shape());\n",
    "    \n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "    return nms;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a5e70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "735163b798c57a729df740099d82825e",
     "grade": false,
     "grade_id": "cell-82b8dc40a69d73c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following two cells to visualize your output. Your edges should be comprised of a single-pixel wide line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9a62b-011a-492c-ba25-a35614127acf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb01a339d2e7e3316cd67bfc7652797c",
     "grade": false,
     "grade_id": "cell-1dc0febc2f7a5725",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_cross200_magphase img_circle200_magphase\n",
    "%put img_cross200_nms img_circle200_nms\n",
    "\n",
    "// Apply the nms to the two test images\n",
    "var img_cross200_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(img_cross200_magphase[0]), new Image(img_cross200_magphase[2]), new Image(img_cross200_magphase[3]) \n",
    ").toArray()\n",
    "var img_circle200_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(img_circle200_magphase[0]), new Image(img_circle200_magphase[2]), new Image(img_circle200_magphase[3]) \n",
    ").toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cfe16-2c5d-4eeb-873c-67979cbc9b93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b89f329e4407a0f1a7663af6a12bf13",
     "grade": false,
     "grade_id": "cell-d48120280d76a923",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JavaScript images to numpy arrays\n",
    "img_cross200_nms = np.array(img_cross200_nms)\n",
    "img_circle200_nms = np.array(img_circle200_nms)\n",
    "# Prepare image and title lists for visualization\n",
    "image_list = [img_cross200_magphase[0], img_circle200_magphase[0], img_cross200_nms, img_circle200_nms]\n",
    "title_list = ['Cross200 Magnitude', 'Circle200 Magnitude', 'Cross200 NMS', 'Circle200 NMS']\n",
    "plt.close('all')\n",
    "view1c = viewer(image_list, title=title_list, subplots=(2,2), joint_zoom=True, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8c1d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8ef21f3cf206bd212a4e712424fb092",
     "grade": false,
     "grade_id": "cell-e252f330900ab38a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform a quick sanity check and see if we can locate the maxima in the gradient features of a $7 \\times 7$ **impulse image** computed using `ksize=5`. The 8 pixels around middle one should be highlighted. Run the following three cells to create the test image, apply your nms function to it and perform a small sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91239cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05791fef4db143e9ea20b2e475b48e47",
     "grade": false,
     "grade_id": "cell-bc95580a756bf467",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Create an impulse image\n",
    "impulse = np.zeros((7,7))\n",
    "impulse[3,3] = 1\n",
    "# Compute the gradient features of the impulse image\n",
    "impulse_magphase = np.array(compute_gradient_features(impulse, ksize=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c338c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57e500a2fea74e23ca7cbf19eb0edbbd",
     "grade": true,
     "grade_id": "cell-cad2b60abb7de5fa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get impulse_magphase\n",
    "%put impulse_nms\n",
    "\n",
    "// Apply the nms to the impulse images' gradient features\n",
    "var impulse_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(impulse_magphase[0]), new Image(impulse_magphase[2]), new Image(impulse_magphase[3]) \n",
    ").toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee76f82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "844a8f0b58f25de747cba704772a30a3",
     "grade": false,
     "grade_id": "cell-d6b343c47a9acdce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JavaScript list to numpy array\n",
    "impulse_nms = np.array(impulse_nms)\n",
    "# Prepare image and title lists for visualization\n",
    "image_list = [impulse, impulse_magphase[0], impulse_nms]\n",
    "title_list = ['7x7 Impulse', 'Magnitude', 'NMS with Interpolation']\n",
    "plt.close('all')\n",
    "view = viewer(image_list, title=title_list, subplots=(1,3), joint_zoom=True, widgets=True)\n",
    "# Sanity check    \n",
    "if int(np.sum(impulse_nms)) != 93:\n",
    "    print('WARNING!\\nYour function did not suppress the right pixels or you modified their values.')\n",
    "else:\n",
    "    print('Congratulations! Your non-maximum suppression passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2d112",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21ad0053ee1ac502e66f86dd66129cf7",
     "grade": false,
     "grade_id": "cell-57f02495175b2e2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Multiple Choice Question\n",
    "\n",
    "* Q1: Now that you have passed the sanity check, can you tell why the lines in the Cross200 image are not exacly straight?\n",
    "\n",
    "    1. The gradients are not accurate enough to properly distinguish the interpolated pixels.\n",
    "    2. Because the for loops explore the image pixel by pixel, when two maxima are close, one gets chosen because it came first.\n",
    "    3. We forgot to normalize the image before converting its pixel values to floating-point numbers.\n",
    "    4. It is caused by the noise and limited blurring effect.\n",
    "    \n",
    "In the next cell, **for $1$ point**, modify the variable `answer_one` to reflect your answer. The following cell is for you to check that your answer is in the valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161408b",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2a1d8ea4224d48fc20fe1badefbb4b4",
     "grade": false,
     "grade_id": "cell-63de9952b02fa718",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Modify this variable to reflect your answer\n",
    "answer_one = None\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd007bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3f85c4de03416a5f9b3eeb4ffd53882",
     "grade": true,
     "grade_id": "cell-ca3b902111de0c00",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Sanity check\n",
    "if not answer_one in [1, 2, 3, 4]:\n",
    "    print('WARNING!\\nChoose one of 1, 2, 3 or 4.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b0524-fbfb-4691-9a83-0920be4569c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d0b9c6a061ce5a557e0866443107cc8",
     "grade": false,
     "grade_id": "cell-9e61cb92f6a76b84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class='alert alert-info'>\n",
    "    <b>Note:</b> The idea presented here can be generalised to filter out neural network outputs for object detection. A typical task for these nets is to place bounding boxes around the objects it detects. However, there are many ways one could place such boxes. To select one that fits best, a variant of non-maximum suppresion is applied.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-stomach",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5a28b746d26fd65adbba2d0543122a",
     "grade": false,
     "grade_id": "cell-b2f3328999d4a78f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.D. Hysteresis thresholding (4 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "In this step, the goal is to further narrow down the pixels we would like to keep as edges. The idea is to manually tune two thresholds, $T_{low}$ and $T_{high}$, that divide our pixels into three categories: `'strong'` edges, `'weak'` edges, and `'background'`. Starting from the `'strong'` edges we will track and keep the `'weak'` edges that are connected to them and discard the remaining ones as being part of the `'background'`. \n",
    "\n",
    "<ul>\n",
    "    <li><code>'strong'</code>: pixels we are sure we'd like to keep right off the bat</li>\n",
    "    <li><code>'weak'</code>: uncertain at first, we'll keep them if they are connected to a strong one</li>\n",
    "    <li><code>'background'</code>: we know we don't care about these</li>\n",
    "</ul>\n",
    "\n",
    "For this step we will ask you to **code in JavaScript** the different subfunctions of `thresholdEdgesHysteresis(image, tl, th)`, to make sure that you get a lower level understanding of how this works. First of all, run the next cell to declare the function (and follow the transformation process of the local variable `array`!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-horse",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bfcfa91cc8c462efa725a9c274d3184",
     "grade": false,
     "grade_id": "cell-d84bf1446ea00e0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "function thresholdEdgesHysteresis(image, tl, th) {\n",
    "    var output = new Image(image.shape());\n",
    "    var array = new Image(image.shape());\n",
    "    // initialise array with semantic edge labels \n",
    "    array = labelImageEdges(image, tl, th);\n",
    "    \n",
    "    // track connected edges starting from strong pixels\n",
    "    array = trackAllEdges(array);\n",
    "    \n",
    "    // keep 'strong' edges, discard remaining 'weak' edges as 'background'\n",
    "    array = thresholdEdges(array);\n",
    "    \n",
    "    return array\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-johns",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2a6354f8570f0e318c17268fcaaf48",
     "grade": false,
     "grade_id": "cell-aa93ea4f6c33ed20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "If you read the names of the $3$ functions that you will implement in the cell above, you might already have gotten an idea of the algorithm we want you to implement:\n",
    "<ol>\n",
    "    <li> Assign a semantic value to each pixel:\n",
    "        <ul>\n",
    "            <li><code>'background'</code> if value $\\le T_{low}$</li>\n",
    "            <li><code>'strong'</code> if value $>T_{high}$\n",
    "            <li><code>'weak'</code> otherwise</li>\n",
    "        </ul>\n",
    "    </li> \n",
    "    <li> For each <code>'strong'</code> pixel, <b>recursively</b> track the <code>'weak'</code> edges that are <a href=\"https://en.wikipedia.org/wiki/Pixel_connectivity#8-connected\"><b>8-connected</b></a> to it and make those pixels <code>'strong'</code> as well. i.e. for each <code>'strong'</code> pixel, call your recursive tracking function (<a href=\"https://en.wikipedia.org/wiki/Recursion_(computer_science)\">a little curiosity on recursivity</a>).</li>\n",
    "    <li> Keep <code>'strong'</code> pixels only (set them to <b>255</b>) and discard the remaining <code>'weak'</code> edges as <code>'background'</code> (set them to <b>0</b>).\n",
    "</ol>\n",
    "\n",
    "Following is the picture taken from your course slides that might help.\n",
    "\n",
    "[<center><img src=\"images/edgetrack.png\" width=\"800\"/></center>](images/edgetrack.png)\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "    <b>Technical note on the use of dictionaries:</b> <a href = \"https://en.wikibooks.org/wiki/A-level_Computing/AQA/Paper_1/Fundamentals_of_data_structures/Dictionaries\">dictionaries</a>, a fundamental data structure also called a hashmap. In the next cell we provide a <b>dictionary</b> called <code>edge</code> where the <b>key</b> (of type <code>string</code>) maps to the <b>value</b> (of type <code>int</code>). We can simply access it with <code>edge[key]</code> to get the <code>value</code>. As you can see from the code, we define <code>'strong'</code> as <code>-1</code>, <code>'weak'</code> as <code>-2</code> and <code>'background'</code> as <code>-3</code>. We invite you to look up the documentation, should you need it, and learn how to use it - for your own good. You might find Python has a few cool dictionary tricks that allow for very compact and efficient code. Fortunately, the syntax in Python and Javascript is identical, so we can use the basics seamlessly.\n",
    "</div>\n",
    "\n",
    "In the next cell, **for 1 point**, complete the function `labelImageEdges(array, tl, th)` to implement the first step in the above algorithm description. Then run the cell below that for a quick sanity check. In it, we will define the image `rocky_path`, which is a black-and-white version of the one shown in the course. Through the rest of the section we will track its transformation through the process. If you have any doubt about the algorithm, make sure to understand the answers at every step of the way!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-scope",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10f85c1e2eff8076d3af0083180962ea",
     "grade": false,
     "grade_id": "cell-65509440ae2ee462",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// semantic edge pixel dictionary, mapping labels to numerical values (do not change)\n",
    "var edge = {\n",
    "    'strong':     -1,\n",
    "    'weak':       -2,\n",
    "    'background': -3,\n",
    "};\n",
    "\n",
    "function labelImageEdges(array, tl, th){\n",
    "    for(var i = 0; i < array.nx; i++){\n",
    "        for(var j = 0; j < array.ny; j++){\n",
    "            \n",
    "            // YOUR CODE HERE\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    return array\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-identifier",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35903ff93602298031cfed48c9f6fb86",
     "grade": true,
     "grade_id": "cell-bf74188e167c1da3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%put rocky_path \n",
    "%put rocky_path_lab\n",
    "%put rocky_path_lab_corr\n",
    "// create the test image and it's labelled version\n",
    "rocky_path = [\n",
    "    [0, 9, 0, 0, 0, 0, 5],\n",
    "    [0, 0, 9, 9, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 5, 0, 0],\n",
    "    [5, 5, 0, 0, 9, 0, 0],\n",
    "    [0, 5, 0, 0, 5, 5, 0],\n",
    "    [0, 0, 0, 5, 0, 9, 0],]\n",
    "rocky_path_lab_corr = [\n",
    "    [-3, -1, -3, -3, -3, -3, -2],\n",
    "    [-3, -3, -1, -1, -3, -3, -3],\n",
    "    [-3, -3, -3, -3, -2, -3, -3],\n",
    "    [-2, -2, -3, -3, -1, -3, -3],\n",
    "    [-3, -2, -3, -3, -2, -2, -3],\n",
    "    [-3, -3, -3, -2, -3, -1, -3],]\n",
    "\n",
    "// perform image labelling on the test image\n",
    "var rocky_path_lab = labelImageEdges(new Image(rocky_path), 3, 7).toArray();\n",
    "if(new Image(rocky_path_lab_corr).imageCompare(new Image(rocky_path_lab)) == false) {    \n",
    "    console.log(\"WARNING!!\\nYour image labeling is not quite correct yet\")\n",
    "} else {    \n",
    "    console.log(\"Your image labeling seems to be correct!\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-baghdad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7a059ffefc8d27ac0df52618e55db11",
     "grade": false,
     "grade_id": "cell-88c24e438542d509",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, **for 1 point**, you will implement the tracking process. Complete the functions `trackEdge(array, x, y)`, which begins to track an edge from the location `[x, y]`. The function and parameters are defined as:\n",
    "\n",
    "<ul>\n",
    "    <li><code>array</code> : an image of labelled pixels. Each pixel has either value <code>-1</code> for <code>'strong'</code>, <code>-2</code> for <code>'weak'</code> or <code>-3</code> for <code>'background'</code></li>\n",
    "    <li><code>x</code> and <code>y</code> the coordinates of the pixel, from where you will start / continue the edge tracking</li>\n",
    "</ul>\n",
    "\n",
    "The function does not return any value, instead it directly modifies the input image `array`. Note that, because of the recursivity of the function, the initialization pixel could be any `'strong'` edge, and the result would not change. For example, in the `rocky_path_image`, initialization on locations `[0, 1]` and `[3, 4]` would both give the same result. Here, we have already coded `trackAllEdges`, a function that takes a labelled array as input and iterates every edge, tracking the ones that were labelled as `'strong'`.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "    <b>Hints:</b>\n",
    "    <ul>\n",
    "        <li>Since <code>trackEdge</code> is a recursive function, you will need to call <code>trackEdge</code> from withing <code>trackEdge</code>.</li>\n",
    "    <li>You should not track any edges beyond the boundaries of the image. Depending on your boundary conditions, if not careful, your <code>trackEdge</code> function could start bouncing back and forth between two boundaries of the image, creating an infinite loop.\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Complete the function in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-algebra",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27b4d17f9f3ec73eb38f6ab32a07895",
     "grade": false,
     "grade_id": "cell-666fd805566bb33e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "function trackAllEdges(array){\n",
    "    for(var x = 0; x < array.nx; x++) {\n",
    "        for(var y = 0; y < array.ny; y++) {\n",
    "            if(array.getPixel(x, y) == edge['strong']) {\n",
    "                trackEdge(array, x, y);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return array\n",
    "}\n",
    "\n",
    "function trackEdge(array, x, y) { // separate this in separate cell, with its sanity check\n",
    "    // loop over 8-connected neighbourhood of pixel (x,y) in array and track its connected edges\n",
    "    for(var xi = x-1; xi <= x+1; xi++) {\n",
    "        for(var yj = y-1; yj <= y+1; yj++) {\n",
    "            \n",
    "            // YOUR CODE HERE\n",
    "            \n",
    "        }\n",
    "    }    \n",
    "    return\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-disaster",
   "metadata": {
    "kernel": "JavaScript"
   },
   "source": [
    "As a sanity, let's apply the `trackEdge` function on the `epfl_logo` test image, all the EPFL pixels should be EPFL-RED, except for the top row. Run the next three cells to visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b6aae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6e918883f76c87e6b5d1fe449ef3673",
     "grade": false,
     "grade_id": "cell-fb39d6bf0b315d0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Basic sanity check\n",
    "epfl_logo = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "])\n",
    "epfl_logo[epfl_logo == 0] = -3\n",
    "epfl_logo[epfl_logo == 1] = -2\n",
    "epfl_logo[-1, -1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a9ac4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a1d7a19be6cff5d9d77be60c047f1aa",
     "grade": true,
     "grade_id": "cell-80af95a13890722d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get epfl_logo\n",
    "%put epfl_logo_track\n",
    "\n",
    "// create test image (epfl_logo)\n",
    "var epfl_logo_track = new Image(epfl_logo);\n",
    "// track the edge recursively using trackEdge\n",
    "trackEdge(epfl_logo_track, epfl_logo_track.nx-1, epfl_logo_track.ny-1);\n",
    "// convert image to array for use in Python\n",
    "epfl_logo_track = epfl_logo_track.toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d7d9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecd0106e3f7787061edf3e97c5efd5b7",
     "grade": false,
     "grade_id": "cell-63e702ae164cb41e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert the resulting image to numpy\n",
    "epfl_logo_track = np.array(epfl_logo_track)\n",
    "# Visualize the original image and the tracked edge\n",
    "image_list = [epfl_logo, epfl_logo_track]\n",
    "title_list = ['EPFL Logo', 'EPFL Logo after EdgeTrack']\n",
    "plt.close('all')\n",
    "view = viewer(image_list, title=title_list, subplots=(1,2), joint_zoom=True, widgets=True, pixel_grid=True, cmap = 'Reds', clip_range = [-3, 0])\n",
    "\n",
    "if np.any(epfl_logo_track[1:,:] == -2):\n",
    "    print('WARNING!\\nYour edge tracking function did not detect all of the pixels recursively 8-connected to the bottom right pixel.\\n')\n",
    "else:\n",
    "    print('Congratulations! Your edge tracking function passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-depression",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "489dce7ddb377d208ddac86e295832bc",
     "grade": false,
     "grade_id": "cell-cbb4e337e5499d8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's get to the final step of the algorithm, the thresholding. **For 1 point**, complete the function `thresholdEdges(array)` in the next cell, that takes as input a previously labelled and tracked image, and returns a binary image with **values $\\{0, 255\\}$ for non-edges and edges** respectively. Then, run the cell after that for a final sanity check on the `rocky_path` image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-viewer",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7abe314e392a81500a6736e42e0787d7",
     "grade": false,
     "grade_id": "cell-799df2912ef2c505",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "function thresholdEdges(array){\n",
    "    for(var i = 0; i < array.nx; i++){\n",
    "        for(var j = 0; j < array.ny; j++){\n",
    "            \n",
    "            // YOUR CODE HERE\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    return array\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-roads",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8e6ea1a92abf849988f7d5fab38751f",
     "grade": true,
     "grade_id": "cell-18ba70c2dbb1cee4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%put rocky_path_tracked\n",
    "%put rocky_path_tracked_corr\n",
    "%put rocky_path_thr_corr\n",
    "%put rocky_path_thr\n",
    "// create the test image and it's labelled version\n",
    "rocky_path_tracked_corr = [\n",
    "    [-3, -1, -3, -3, -3, -3, -2],\n",
    "    [-3, -3, -1, -1, -3, -3, -3],\n",
    "    [-3, -3, -3, -3, -1, -3, -3],\n",
    "    [-2, -2, -3, -3, -1, -3, -3],\n",
    "    [-3, -2, -3, -3, -1, -1, -3],\n",
    "    [-3, -3, -3, -1, -3, -1, -3],]\n",
    "\n",
    "rocky_path_thr_corr = [\n",
    "    [0, 255,  0,  0, 0, 0, 0],\n",
    "    [0, 0, 255, 255, 0, 0, 0],\n",
    "    [0, 0, 0,   0, 255, 0, 0],\n",
    "    [0, 0, 0,   0, 255, 0, 0],\n",
    "    [0, 0, 0, 0, 255, 255, 0],\n",
    "    [0, 0, 0, 255, 0, 255, 0],]\n",
    "\n",
    "// perform hysteresis edge tracking on the labelled test image. For completeness, we also extract the tracked version\n",
    "var rocky_path_tracked = trackAllEdges(new Image(rocky_path_lab_corr)).toArray();\n",
    "var rocky_path_thr = thresholdEdges(new Image(rocky_path_tracked_corr)).toArray();\n",
    "if(new Image(rocky_path_thr_corr).imageCompare(new Image(rocky_path_thr)) == false) {    \n",
    "    console.log(\"WARNING!!\\nYour thresholding is not quite correct yet.\")\n",
    "} else {    \n",
    "    console.log(\"Congrats! Your thresholding seems to be correct!\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-indonesia",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecfeb40436f7516b6a1e8d2ffe7a14bf",
     "grade": false,
     "grade_id": "cell-c89809c385795e11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Nice! You have now implemented the three steps in hystheresis thresholding. Let's now look at the bigger picture and re-run the function `thresholdEdgesHysteresis`. Run the next cell to compute the final output. Then run the Python cell after that to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1339e30",
   "metadata": {
    "kernel": "JavaScript"
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%put rocky_path_tlh\n",
    "\n",
    "// perform hysteresis edge tracking on the test image\n",
    "var rocky_path_tlh = thresholdEdgesHysteresis(new Image(rocky_path), 3, 7).toArray();\n",
    "if(new Image(rocky_path_thr_corr).imageCompare(new Image(rocky_path_tlh)) == false) {    \n",
    "    console.log(\"WARNING!!\\nYour hystheresis thresholding is not quite correct yet. Look at the feedback from the indvidual functions for detail!\")\n",
    "} else {    \n",
    "    console.log(\"Congrats! Your hystheresis thresholding workflow seems to be perfect!\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-religious",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "317fc83eb79b74f65f2590309bff8e84",
     "grade": false,
     "grade_id": "cell-1973574e4581204f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert initial JS arrays to numpy\n",
    "rocky_path = np.array(rocky_path)\n",
    "rocky_path_tlh = np.array(rocky_path_tlh)\n",
    "rocky_path_thr_correct = np.array(rocky_path_thr_corr)\n",
    "\n",
    "if np.allclose(rocky_path_tlh, rocky_path_thr_correct):\n",
    "    print('Congrats! You seemed to have mastered hystheresis thresholding. Take a look at the replication of the course image below.') \n",
    "    # Visualize the original and result image\n",
    "    image_list = [rocky_path, rocky_path_tlh]\n",
    "    title_list = ['Rocky Path', 'Rocky Path after Hysteresis']\n",
    "    plt.close('all')\n",
    "    view = viewer(image_list, title=title_list, subplots=(1,2), joint_zoom=True, widgets=True, pixel_grid=True)\n",
    "else :\n",
    "    print('WARNING!!!\\nSomething s not quite correct yet. You have already gotten some feedback before, but take a look at the following viewer with the \\\n",
    "          the correct steps of the process in comparison to your implementations. Remember that each of the steps is evaluated separately, with the correct input.') \n",
    "    rocky_path_lab_correct = np.array(rocky_path_lab_corr)\n",
    "    rocky_path_lab = np.array(rocky_path_lab)\n",
    "    rocky_path_tracked_correct = np.array(rocky_path_tracked_corr)\n",
    "    rocky_path_tracked = np.array(rocky_path_tracked)\n",
    "    rocky_path_thr = np.array(rocky_path_thr)\n",
    "    image_list = [rocky_path_lab_correct, rocky_path_tracked_correct, rocky_path_thr_correct, rocky_path_lab, rocky_path_tracked, rocky_path_thr]\n",
    "    title_list = ['GT Labeling', 'GT Edge Tracking', 'GT Binarization', 'Labeling', 'Edge Tracking', 'Binarization']\n",
    "    view = viewer(image_list, title=title_list, subplots=(2,3), joint_zoom=True, widgets=True, pixel_grid=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96309c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8146772b6beed582e241c3600b177b09",
     "grade": false,
     "grade_id": "cell-45d807f2d1809e4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have passed all sanity checks, let's take a look at the output of our final edge detection stage on Cross200 and Circle200. Run the next two cells and observe the output edges. Go back to your implementation if it doesn't feel quite right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f5001-cb66-48f2-8833-593c75dea2ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ec1c0a22f46646c6a0604cde8dd2989",
     "grade": false,
     "grade_id": "cell-7abdd3c265021497",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_cross200_nms img_circle200_nms \n",
    "%put img_cross200_tlh img_circle200_tlh tl th\n",
    "// set the thresholds\n",
    "var tl = 50;\n",
    "var th = 100;\n",
    "// apply the hysteresis edge tracking to the non-maximum suppresion images of the two test images\n",
    "var img_cross200_tlh = thresholdEdgesHysteresis(new Image(img_cross200_nms), tl, th).toArray();\n",
    "var img_circle200_tlh = thresholdEdgesHysteresis(new Image(img_circle200_nms), tl, th).toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5264c4-c39e-4288-a355-14a31ba0e910",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afd423d1cbdbe7a7f92d5c685aee7e97",
     "grade": false,
     "grade_id": "cell-36aed42b48d3cf43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "img_cross200_tlh = np.array(img_cross200_tlh)\n",
    "img_circle200_tlh = np.array(img_circle200_tlh)\n",
    "# Display the two test images and their edges\n",
    "image_list = [img_cross200, img_circle200, img_cross200_tlh, img_circle200_tlh]\n",
    "title_list = ['Cross200', 'Circle200', f'Cross200 Canny (Tl={tl} Th={th})', f'Circle200 Canny (Tl={tl} Th={th})']\n",
    "plt.close('all')\n",
    "view1d1 = viewer(image_list, title=title_list, subplots=(2,2), joint_zoom=True, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461a3b6-ec0a-44b9-9f5a-7bc907b2721b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1f86eb76b5828ec91d536a2c66b2e25",
     "grade": false,
     "grade_id": "cell-952028fd2bbca2b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will now experiment with setting the threshold values. In the following three cells, we pass a new GrayFig image through the steps you just coded. Test your understanding by answering the following MCQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc477c8d-b8e8-4142-9b14-a6321d398853",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4c3cf9741a9ce0690d5e6b3b7a34309",
     "grade": false,
     "grade_id": "cell-983032f7a4b9794f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Apply Gaussian blurring to grayfig image\n",
    "img_grayfig_blur = smooth_gaussian(img_grayfig)\n",
    "# Compute gradient features of the grayfig image\n",
    "img_grayfig_magphase = np.array(compute_gradient_features(img_grayfig_blur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be82bc-aae0-439d-9a77-533dd531c9af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0894064a43d660b54a54a4036a50d004",
     "grade": false,
     "grade_id": "cell-9bb9635bbc042775",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_grayfig_magphase\n",
    "%put img_grayfig_nms \n",
    "%get tl th\n",
    "%put img_grayfig_tlh\n",
    "// Apply the non-maximum suppression to the gradient features of the grayfig image\n",
    "var img_grayfig_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(img_grayfig_magphase[0]), new Image(img_grayfig_magphase[2]), new Image(img_grayfig_magphase[3]) \n",
    ").toArray();\n",
    "// Perform hysteresis edge tracking on the nms output of the grayfig image\n",
    "var img_grayfig_tlh = thresholdEdgesHysteresis(new Image(img_grayfig_nms), 10, 20).toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec905538-eb42-4a6e-b515-52b194173f99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "404e38770a4da4890947edd739e496ff",
     "grade": false,
     "grade_id": "cell-89fd043ff5a1813e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "img_grayfig_nms = np.array(img_grayfig_nms) \n",
    "img_grayfig_tlh = np.array(img_grayfig_tlh) \n",
    "# Display the different stages of the algorithm \n",
    "image_list = [img_grayfig, img_grayfig_blur, img_grayfig_nms, img_grayfig_tlh]\n",
    "title_list = ['GrayFig Original', 'GrayFig Blurred', 'GrayFig NMS', f'GrayFig Canny (Tl={10} Th={20})']\n",
    "plt.close('all')\n",
    "view1d2 = viewer(image_list, title=title_list, subplots=(2,2), joint_zoom=True, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffad03e-40d7-413b-b6db-f3f579c00eda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f37b545bdcc50597ebfd5bef33e44692",
     "grade": false,
     "grade_id": "cell-bcda82909186632e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Multiple Choice Question\n",
    "\n",
    "* Q1: Which pair of thresholds `tl`, `th` would allow you to suppress the cross inside the inner (black) circle while retaining the rest of the lines on the outside ? Try to guess from the pixel values and build an intuition :-)\n",
    "\n",
    "    1. 100, 130\n",
    "    2. 60, 100\n",
    "    3. 40, 70\n",
    "    4. 50, 200\n",
    "    \n",
    "In the next cell, modify the variable `answer` to reflect your answer. The following cell is for you to check that your answer is in the valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcb01e-6035-47be-91ea-4d19adc307a6",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb12e2062e08b6b50faba720cbe631be",
     "grade": false,
     "grade_id": "cell-1fe1c59876a18dda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Modify these variables\n",
    "answer = None\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f283550-e0f0-43ce-abef-2eddc7b88187",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f5b2096fc7f816633c02729cc213e3f",
     "grade": true,
     "grade_id": "cell-03339daf293cc0a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Sanity check\n",
    "if not answer in [1, 2, 3, 4]:\n",
    "    print('WARNING!\\nChoose one of 1, 2, 3 or 4.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701c0e7-161d-449c-b82b-d20f13845e54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61e30443cbf56bdf907143e35a983f25",
     "grade": false,
     "grade_id": "cell-6d8d789469c3a6ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Congratulations! You have now implemented all the building blocks of the Canny edge detector. It's time to try it out and compare your edges to the ones of OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2862f4-d7e2-4b6d-b9b9-389da264d7ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fd22f87b3426c9e5458fe6129a22b62",
     "grade": false,
     "grade_id": "cell-e5a9a2098b7620e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.E. Comparison with OpenCV\n",
    "\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "In the next cell let us first define our comparison utility function. It will return an image where <b><i>red</i> pixels are edges your implementation has but OpenCV doesn't and <i>green</i> are pixels your implementation doesn't have but OpenCV does</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baebe24-8014-4d3f-adb6-eba7dca1623e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3fa8a30a50ed246e44eec9d06176164",
     "grade": false,
     "grade_id": "cell-28d5ceb40e17cee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that highlights the difference between two images\n",
    "def compare_difference(mystack, opencv, print_diff=False):\n",
    "    # unpack stack, variables could come useful for some during debug\n",
    "    image, blur, mag, phase, gradx, grady, nms, tlh = mystack\n",
    "    # label differences\n",
    "    diff_img = cv.normalize(cv.cvtColor(np.float32(opencv), code=cv.COLOR_GRAY2RGB), \n",
    "                            None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)\n",
    "    diff_img[opencv > tlh] = [0, 255, 0] # GREEN: opencv has this pixel\n",
    "    diff_img[opencv < tlh] = [255, 0, 0] # RED: opencv doesn't have this pixel\n",
    "    # compute similarity\n",
    "    diff_str = f'Original = OpenCV @ {100*(1-np.mean(tlh != opencv)):.3f}%'\n",
    "\n",
    "    return diff_img, diff_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43c4b4-896c-448a-82f9-9e52ad9f36af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "146a75b7697a4bb036bf24a23bef722a",
     "grade": false,
     "grade_id": "cell-edb505354daf7721",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's compare your implementation to what OpenCV returns as edges for the image Object. First we define the parameters and apply the workflow that you have coded so far. Run the next two cells to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb0aec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daacf593f249cb6c3baa311771ada16b",
     "grade": false,
     "grade_id": "cell-9d0b2c252e73fbb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Set the parameters\n",
    "sigma = 1.2\n",
    "ksize = 3\n",
    "tl, th = 10, 20\n",
    "# Perform Gaussian blurring\n",
    "img_object_blur = smooth_gaussian(img_object, sigma=sigma)\n",
    "# Compute the gradient features for the JS function\n",
    "img_object_magphase = np.array(compute_gradient_features(img_object_blur, ksize=ksize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33455ae6-1fdf-49e0-beb2-645f173a8e0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d891412535b83b167730aa6aa3fa8569",
     "grade": false,
     "grade_id": "cell-92f2f6eccea36d55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_object_magphase\n",
    "%put img_object_nms\n",
    "%get tl th\n",
    "%put img_object_tlh\n",
    "// Apply non-maximum suppression \n",
    "var img_object_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(img_object_magphase[0]), new Image(img_object_magphase[2]), new Image(img_object_magphase[3]) \n",
    ").toArray();\n",
    "var img_object_tlh = thresholdEdgesHysteresis(new Image(img_object_nms), tl, th).toArray();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d4752",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54173e617070cd8947eb546ba2edcea2",
     "grade": false,
     "grade_id": "cell-e0fe0f89bbc1302d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell we use [`cv.Canny(src, threshold1, threshold2, apertureSize, L2gradient)`](https://docs.opencv.org/4.x/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de) to perform pure Python edge detection on `img_object`, and assign the value to `img_object_cv`. The cell below the next one will display both results, so you can compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657aa26-4ef9-45db-8c28-ad3da6829fd1",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb8ca97f43136cf50f027ba41088ee5",
     "grade": false,
     "grade_id": "cell-2fcb4471c818be3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Perform Canny edge detection in Python using cv.Canny\n",
    "img_object_cv = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89226c3d-8c15-4121-a809-7337a1a5f727",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe7c413c5157ad895a3f817e0ca90804",
     "grade": false,
     "grade_id": "cell-3eea85b1b9ee5d4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "img_object_nms = np.array(img_object_nms) \n",
    "img_object_tlh = np.array(img_object_tlh)\n",
    "# Gett the difference between the two results\n",
    "diff = compare_difference([img_object, img_object_blur, *img_object_magphase, img_object_nms, img_object_tlh], img_object_cv)\n",
    "# Display the results\n",
    "image_list = [img_object, img_object_tlh, img_object_magphase[0], img_object_cv, img_object_magphase[1], diff[0]]\n",
    "title_list = ['Image Object', 'Original Canny', 'Magnitude', 'OpenCV Canny', 'Phase', diff[1]]\n",
    "plt.close('all')\n",
    "view1f = viewer(image_list, title=title_list, subplots=(3,2), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a635ad7-7334-4c0e-acb2-a7a8dc27d728",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3987465ebf7fb105b1d013671c4879fe",
     "grade": false,
     "grade_id": "cell-1a7cc7d240994e48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You may be disappointed, don't worry, no points are involved in this one. In fact, no matter how you called that last function, the outputs are different. We just wanted you to open up the documentation.\n",
    "\n",
    "After digging through OpenCV's implementation we can tell you why you see what you see. Going stage by stage, these are the differences :\n",
    "<ol>     \n",
    "    <li>For noise reduction, <b>OpenCV does not apply gaussian smoothing on the image</b>.\n",
    "        <ul>\n",
    "            <li>They rely on the inherent smoothing of the sobel operator. This explains why they have the apertureSize parameter which you have ignored so far. One can increase it for more blurring effect.</li>\n",
    "            <li>We will provide OpenCV our blurred image directly</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>For magnitude computation, OpenCV uses L1-norm to compute the magnitude, by default. We assume this is to save some extra computations at little performance cost.</li>\n",
    "    <br>\n",
    "    <li>For non-maximum suppression <b>OpenCV does not use interpolation</b>. \n",
    "        <ul>\n",
    "            <li>Instead, they round the phase and take the nearest pixel in that direction. Since they do this, they do not even bother computing the phase and use mathemagic tricks to classify the direction of interest directly. However, this implies they <i>cheat</i> on the exactness of the maximum and we will show you how. It has to do with the <i>strict</i> vs <i>or equal</i> comparisons of neighbouring pixels.</li>\n",
    "            <li>This also allows for some slackness for OpenCV to detect an edge where our implementation requires further blurring to ensure a maximum.</li>\n",
    "            <li>If you really zoom in, you will notice the OpenCV implementation is asymmetric (keep in mind the original image might be asymmetric).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>For hysteresis thresholding, let's just say our algorithm is a bit more sensible to these labs but overall this stage's outputs are identical.</li>\n",
    "    <br>\n",
    "    <li>In general, we'd like to bring your attention to the matter of boundary conditions. We have chosen to use mirror boundaries but this is not the case for OpenCV. This allows them to classify more boundary pixels as edges.</li>\n",
    "    <li>Finally, the fact that <b>OpenCV only accepts <code>uint8</code> input images</b> leads to numerical differences from the very start.\n",
    "</ol>\n",
    "\n",
    "That presents quite a few reasons and any combination of the above could explain why the images differ. We will go through them in the second half of this first part but we've spared you most of the trouble already. You might want to skim through their [code on github](https://github.com/opencv/opencv/blob/4.x/modules/imgproc/src/opencl/canny.cl), the implementation is super efficient.\n",
    "\n",
    "<a id=\"last_part_comp_opencv\"></a>\n",
    "Using the following four cells, we invite you to visualize the differences on the images we introduced at the beginning of this notebook and experiment with some parameters. In particular, why not try images 3, 4 and 10 (which we will reuse) or explore the L1 vs L2 difference, for example? We apologize for not being able to provide interactive widgets to make this less tedious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ecc80-a42b-450b-be49-2759acebd059",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Choose 1 out of 11 images [0..10]\n",
    "img = images_list[-1]\n",
    "# Set your parameters (ignore ksize and borderType)\n",
    "sigma = 2\n",
    "ksize = 3\n",
    "tl, th = 10, 20\n",
    "l2grad = True\n",
    "\n",
    "# Apply Gaussian smoothing\n",
    "blur = smooth_gaussian(img, sigma=sigma)\n",
    "# Compute the gradient features\n",
    "magphase = np.array(compute_gradient_features(blur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fbbad-ca71-4ec1-b60d-8df72fe2fb5a",
   "metadata": {
    "kernel": "JavaScript",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get magphase\n",
    "%put nms \n",
    "%get tl th\n",
    "%put tlh\n",
    "// Apply the non-maximum suppression to the gradient features\n",
    "var nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(magphase[0]), new Image(magphase[2]), new Image(magphase[3]) \n",
    ").toArray();\n",
    "// Perform hysteresis edge tracking on the nms output\n",
    "var tlh = thresholdEdgesHysteresis(new Image(nms), tl, th).toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8fc1be-53c0-4cbf-9236-b50a3b99591e",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "nms = np.array(nms) \n",
    "tlh = np.array(tlh)\n",
    "\n",
    "# Perform numpy Canny edge detection\n",
    "opencv = cv.Canny(np.uint8(img), threshold1=tl, threshold2=th, apertureSize=ksize, L2gradient=l2grad)\n",
    "\n",
    "# Get the differences between the two versions\n",
    "diff = compare_difference([img, blur, *magphase, nms, tlh], opencv)\n",
    "# Display the differences\n",
    "image_list = [img, tlh, magphase[1], opencv, nms, diff[0]]\n",
    "title_list = ['Original', 'My Canny', 'Phase', 'OpenCV', 'NMS', diff[1]]\n",
    "plt.close('all')\n",
    "view1e2 = viewer(image_list, title=title_list, subplots=(3,2), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0c3f9-4c9e-4730-af7c-835be14da4df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9ff908c1d728d1cad049700af3dfdc1",
     "grade": false,
     "grade_id": "cell-86921910274d2e29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.F. The switch to OpenCV (2 points)\n",
    "\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "As we have presented in the previous section the differences our implementation has with OpenCV, we will now make the adjustments necessary to match the implementation exactly. You will then be able to better tell if you made a mistake in your above implementation.\n",
    "\n",
    "Since we already set you up with easy ways to modify what needs to be changed the first time around, let's just reimplement the non-maximum suppression stage.\n",
    "\n",
    "Again, we will ask that you to code in Javascript to get a lower level understanding of how this works. Your task, **for 2 points**, is to implement the function `applyNonMaximumSuppressionRound45deg`.\n",
    "\n",
    "In this function, you will examine the gradient magnitude value with its 8-connected neighbors:\n",
    "\n",
    "<center><img alt=\"8-connected neighbors\" src=\"images/8-connected.png\" width=\"300\"></center>\n",
    "\n",
    "whether its value is greater than its two neighbours along the horizontal, vertical, diagonal and antidiagonal directions. If this is the case, we will keep it, otherwise we will discard it. \n",
    "\n",
    "Specifically, greater means **greater or equal** for the neighboring pixels directly below or to the right and **strictly greater** for the others (check the visualization below): \n",
    "\n",
    "<ul>\n",
    "    <li>$(x-1, y) < (x, y)  \\ge  (x+1, y)$</li>\n",
    "    <li>$(x, y-1) < (x, y)  \\ge  (x, y+1)$</li>\n",
    "    <li>$(x-1, y-1) < (x, y)  >  (x+1, y+1)$</li>\n",
    "    <li>$(x-1, y+1) < (x, y)  >  (x+1, y-1)$</li>\n",
    "    </ul>\n",
    "\n",
    "Furthermore, use **zero padding**. You may do so directly through `getPixel(x, y, padding='zero')`.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** These asymmetric comparisons favor detection in the bottom right direction whereas our implementation is isotropic. The strict comparisons in the diagonals aim to compensate for the greater distance, which our comparisons based on uniform gradient vectors does not require. Although quite imprecise at first, from a pure image processing point of view, the choices are very well balanced and the differences remain subtle in most applications.\n",
    "</div>\n",
    "\n",
    "The function and its parameters are defined as:\n",
    "\n",
    "<code>applyNonMaximumSuppressionRound45deg(image, phase)</code>\n",
    "<ul>\n",
    "    <li><code>image</code> : An <code>Image</code> object that contains the magnitude of the gradient at each pixel</li>\n",
    "    <li><code>phase</code> : An <code>Image</code> object that contains the direction of the gradient at each pixel</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dc354",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e86c3aae582aee0c85a4f4abfc1b3574",
     "grade": false,
     "grade_id": "cell-d13a39226ad3a8ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "function applyNonMaximumSuppressionRound45deg(image, phase) {\n",
    "    var out = new Image(image.shape());\n",
    "    \n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "    return out;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c13e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee21bb97e388eec32ca149280fdee472",
     "grade": false,
     "grade_id": "cell-45b98f149fd7be3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform a quick sanity check using the gradient features of a randomized image computed using `ksize=3`. This should highlight the differences between `Interpolation` and `Round45deg` non-maxima suppressions. The interpolated version should give better boudaries for the middle three squares, whereas the rounding version should detect the bottom left square due to the adjusted boundary conditions (you might want to go back to the interpolation if this doesn't feel right). Run the following three cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68803f69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "832dcf56d60128435aceeaba0b1b0db9",
     "grade": false,
     "grade_id": "cell-1b5ce0eb31559fd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Create the test image\n",
    "img_rand = np.zeros((7,7))\n",
    "img_rand[1,5] = img_rand[2,2] = img_rand[3,3] = img_rand[4,4] = img_rand[6,0] = 1\n",
    "img_rand_magphase = np.array(compute_gradient_features(img_rand, ksize=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473eee7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77bdf9868cd9646a7b582685eaec46d3",
     "grade": true,
     "grade_id": "cell-30acb7dfcb9099ff",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_rand_magphase\n",
    "%put img_rand_nms_i img_rand_nms_r\n",
    "// apply the round version of nms on the test image\n",
    "var img_rand_nms_r = applyNonMaximumSuppressionRound45deg(\n",
    "    new Image(img_rand_magphase[0]), new Image(img_rand_magphase[1]) \n",
    ").toArray();\n",
    "// apply the interpolation version of nms on the test image\n",
    "var img_rand_nms_i = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(img_rand_magphase[0]), new Image(img_rand_magphase[2]), new Image(img_rand_magphase[3]) \n",
    ").toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961e9c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88f4ee91edc5436c812e94189b0b9050",
     "grade": false,
     "grade_id": "cell-395e4f631308d1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "img_rand_nms_i = np.array(img_rand_nms_i)\n",
    "img_rand_nms_r = np.array(img_rand_nms_r)\n",
    "# Visualize the outputs\n",
    "image_list = [img_rand, np.zeros_like(img_rand), img_rand_magphase[0], img_rand_magphase[1], img_rand_nms_i, img_rand_nms_r]\n",
    "title_list = ['Randomised Image', 'Intentionally Blank', 'Magnitude', 'Gradient Direction', 'NMS with Interpolation', 'NMS with Round to 45deg']\n",
    "plt.close('all')\n",
    "view = viewer(image_list, title=title_list, subplots=(3,2), joint_zoom=True, widgets=True)\n",
    "# Sanity check, counting the pixel values of the output\n",
    "if int(np.sum(impulse_nms)) != 93:\n",
    "    print('WARNING!\\nYour function did not suppress the right pixels or you modified their values.')\n",
    "else:\n",
    "    print('Congratulations! Your non-maximum suppression passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edbb48d-d960-4225-a2bc-35d813423809",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccdbd4ed5c260d1df8744fd13c65aefb",
     "grade": false,
     "grade_id": "cell-5e923e22f3f22cd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that perform the same orientation rounding as OpenCV, the last thing to change is to call your `compute_gradient_features` with `sigma=None`, to not apply any blurring, and with `borderType=cv.BORDER_REPLICATE`, so that we're using the same boundary condition as OpenCV. Again, remember that in image processing, border conditions do make a difference. Now that we have established fair play, let's compare your implementation to the one of OpenCV using the Grayfig image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52051fd-a998-4596-9fef-1dc921060caf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a75ee10114a2b2f09ed60a709a8be5e",
     "grade": false,
     "grade_id": "cell-96de72192fe1b5d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Define the parameters\n",
    "sigma = None  # explicitely not used\n",
    "ksize = 3\n",
    "tl, th = 10, 20\n",
    "# Convert the test image to uint8 to match OpenCV\n",
    "img_canny = np.uint8(img_grayfig)\n",
    "# Compute the gradient features\n",
    "img_grayfig_magphase_r = np.array(compute_gradient_features(img_grayfig, ksize=ksize, borderType=cv.BORDER_REPLICATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccca5ac-485f-484f-acf1-427cc05ac506",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff33c1f18b0a60ae4481469eb4c11daf",
     "grade": false,
     "grade_id": "cell-3be0f6d2cc07345f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get img_grayfig_magphase_r\n",
    "%put img_grayfig_nms_r\n",
    "%get tl th\n",
    "%put img_grayfig_tlh_r\n",
    "// apply the rounding nms\n",
    "var img_grayfig_nms_r = applyNonMaximumSuppressionRound45deg(new Image(img_grayfig_magphase_r[0]),\n",
    "                                                             new Image(img_grayfig_magphase_r[1]) ).toArray();\n",
    "// apply hysteresis edge tracking\n",
    "var img_grayfig_tlh_r = thresholdEdgesHysteresis(new Image(img_grayfig_nms_r), tl, th).toArray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fc485-9554-4f28-8c4c-bc6438db1189",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27fffd46ce93be8e98649c4c754cc15e",
     "grade": false,
     "grade_id": "cell-f2f3b6e155748603",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "img_grayfig_nms_r = np.array(img_grayfig_nms_r) \n",
    "img_grayfig_tlh_r = np.array(img_grayfig_tlh_r)\n",
    "# Apply the OpenCV Canny edge detection\n",
    "img_grayfig_cv_r = cv.Canny(img_canny, threshold1=tl, threshold2=th, apertureSize=ksize, L2gradient=True)\n",
    "# Get the difference between the two versions\n",
    "diff_r = compare_difference([img_grayfig, None, *img_grayfig_magphase_r, img_grayfig_nms_r, img_grayfig_tlh_r], img_grayfig_cv_r)\n",
    "# Visualize the results\n",
    "image_list=[img_grayfig_tlh_r, img_grayfig_cv_r, diff_r[0]]\n",
    "title_list=['Original', 'OpenCV', diff_r[1]]\n",
    "plt.close('all')\n",
    "view1f = viewer(image_list, title=title_list, subplots=(1,3), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656d194-9be2-4045-851f-27bca519285e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "278094fe18e2361109bc9c081506b6d1",
     "grade": false,
     "grade_id": "cell-c0aaa46f2be7276d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since you took the time to code both implementations, you might want to observe the differences of using the interpolated vs rounded versions of non-maximum suppression. We invite you to go back to the [last part of *Comparison with OpenCV*](#last_part_comp_opencv) and change `applyNonMaximumSuppressionInterpolation` to `applyNonMaximumSuppressionRound45deg`. You may need to zoom in to appreciate the differences, and/or better understand why OpenCV decided not to interpolate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af92d31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07855c1167b2df1b049aa584828d402b",
     "grade": false,
     "grade_id": "cell-4ebbd1aa3d7e4e73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Original ridge detector (3 points)\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "The original ridge detector we will implement in this section will make use of the building blocks of the Canny edge detector. We will be able to reuse most of the Canny edge detector's pipeline. \n",
    "\n",
    "The ridge detection algorithm is as follows.\n",
    "1. Noise reduction\n",
    "2. Figure of merit and eigenvector orientation based on the Hessian matrix\n",
    "3. Non-maximum suppression\n",
    "4. Hysteresis thresholding\n",
    "\n",
    "As portrayed by the following diagram, you implemented most of these already, only the second step will get replaced by features of the Hessian (instead of the gradient). \n",
    "\n",
    "[<img src=\"images/ridge_detector_schematic.png\" width=\"800\"/>](images/ridge_detector_schematic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e9e66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "359a9e23a14dafdf18313d7f71b332bc",
     "grade": false,
     "grade_id": "cell-547a010031241a0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.A. Motivation\n",
    "\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "Go ahead and run the next cell to visualise the limitations of the edge detector. If you observe attentively the output of the edge detector, you will see that for each line we get two edges. In some applications it can be useful to detect only the ridge line (vessels in the next figure). This is what we would like our ridge detector to do, with very little modifications to our edge detection pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e77cb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "167513beb7e296b35247decd84bf5d31",
     "grade": false,
     "grade_id": "cell-0e89fcb5d7e15eb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Visualize the fungus image\n",
    "image_list = [img_fundus, cv.Canny(img_fundus, threshold1=70, threshold2=120, apertureSize=3, L2gradient=True)]\n",
    "title_list = ['Fundus Original','Fundus Edges']\n",
    "plt.close('all')\n",
    "view2a = viewer(image_list, title=title_list, subplots=(1,2), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f717b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71b886c4f9849ea2bb7ec21b79f7e06b",
     "grade": false,
     "grade_id": "cell-4dced1e15f702295",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.B. Implementation (3 points)\n",
    "\n",
    "[Back to table of contents](#ToC_2_Feature_detection)\n",
    "\n",
    "\n",
    "Following the explanation given in the introduction, we will now guide you through the computation of the [Hessian matrix](https://en.wikipedia.org/wiki/Hessian_matrix) features used by the ridge detection algorithm.\n",
    "\n",
    "In the next cell, we define a utility function that will return the eigenvector associated to the provided eigenvalue and Hessian matrix elements. The inputs and outputs are all images so you will need to call this function only once.\n",
    "\n",
    "In the following cell, **for 3 points**, implement `compute_hessian_features(image, ksize, borderType)`. Just as for the gradient features, use the OpenCV Sobel filter [`cv.Sobel`](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d) to compute the elements of the Hessian matrix and follow the comments in the code to compute the desired outputs.\n",
    "\n",
    "The function and its input parameters is defined as:\n",
    "\n",
    "`compute_hessian_features(image, ksize, borderType)`\n",
    "* `image` : The input image, from where we want to compute the features\n",
    "* `ksize` : The size of the Sobel filter\n",
    "* `borderType` : The boundary conditions to use for the Sobel filter\n",
    "\n",
    "The function returns:\n",
    "* `merit` : An image containing the **figure of merit** (see hints) for each pixel\n",
    "* `orientation` : An image containing the orientation of the **eigenvector associated to the minimum eigenvalue** for each pixel\n",
    "* `vminX` : An image containing the x-component of the eigenvector associated to the minimum eigenvalue for each pixel\n",
    "* `vminY` : An image containing the y-component of the eigenvector associated to the minimum eigenvalue for each pixel\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Important:</b> Use the utility function <code>get_hessian_eigenvector(eigenvalue, hessianXX, hessianXY, hessianYY)</code> to get the x- and y-components of the eigenvector associated to a given eigenvalue and the Hessian matrix elements.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Hints:</b> \n",
    "<ul>\n",
    "    <li><code>cv.Sobel</code>: set <code>ddepth=cv.CV_64F</code> since the gradient can be a negative floating point number.</li>\n",
    "    <li><code>cv.Sobel</code>: You can set the order of the <code>x</code>- and/or <code>y</code>-derivative you want to generatate by setting <code>dx=order_x</code> and <code>dy=order_y</code>.</li>\n",
    "    <li>The hessian matrix is symmetric.</li>\n",
    "    <li>The figure of merit is defined as $fom=\\sqrt{|\\lambda_{min}| |\\lambda_{min} - \\lambda_{max}|}$, where $\\lambda_{min}$ and $\\lambda_{max}$ are the minimum and maximum eigenvalues of the Hessian matrix respectively.</li>\n",
    "    <li><code><a href=\"https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html\" style=\"color:black\">np.arctan2</a></code>: could help you get the correct orientation in all four quadrants.</li>\n",
    "    <li>To ensure that you define the correct parameter in a function call always specify the name of the parameter.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68332a4-9d1a-4519-9e6f-494b77cb2193",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7614a313561c859ae3f8b8ffd9ccb8a",
     "grade": false,
     "grade_id": "cell-2ae9359f2e70ba75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that returns the eigenvector associated to a given eigenvalue and the Hessian matrix elements\n",
    "def get_hessian_eigenvector(eigenvalue, hessianXX, hessianXY, hessianYY):\n",
    "    # compute a normalized eigenvector of [[Hxx, Hxy],[Hyx, Hyy]] associated to lmin: [vminX, vminY].T\n",
    "    vx = np.zeros(hessianXX.shape)\n",
    "    vy = np.zeros(hessianXX.shape)\n",
    "    norm = np.ones(hessianXX.shape)   \n",
    "    \n",
    "    # sometimes the norm of the computed eigenvector is nil and we can take the other eigenvector to compensate\n",
    "    # ignore situations where both are nil simultaneously as the figure of merit is irrelevant (0)\n",
    "    # get first eigenvectors (values default to zero by init)\n",
    "    v1 = np.array([hessianXY, eigenvalue - hessianXX]) \n",
    "    norm1 = np.sqrt(v1[0]**2 + v1[1]**2)\n",
    "    vx[norm1 > 0] = v1[0][norm1 > 0] / norm1[norm1 > 0]\n",
    "    vy[norm1 > 0] = v1[1][norm1 > 0] / norm1[norm1 > 0]\n",
    "    # override or complete first eigenvectors with second eigenvectors\n",
    "    v2 = np.array([eigenvalue - hessianYY, hessianXY])\n",
    "    norm2 = np.sqrt(v2[0]**2 + v2[1]**2)\n",
    "    vx[norm2 > 0] = v2[0][norm2 > 0] / norm2[norm2 > 0]\n",
    "    vy[norm2 > 0] = v2[1][norm2 > 0] / norm2[norm2 > 0]\n",
    "    \n",
    "    return vx, vy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ab50d",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a176d82905b83cc7208e2329c65db853",
     "grade": false,
     "grade_id": "cell-5e200ae43b75dad0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that computes the Hessian features of a given input image\n",
    "def compute_hessian_features(image, ksize=3, borderType=cv.BORDER_REFLECT):\n",
    "    merit = np.zeros(image.shape)\n",
    "    orientation = np.zeros(image.shape)\n",
    "    vminX = np.zeros(image.shape)\n",
    "    vminY = np.zeros(image.shape)\n",
    "\n",
    "    # Compute the Hessian matrix elements (xx, xy, and yy) using the cv.Sobel function with different orders of dx and dy\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Solve the characteristic polynomial equation to determine the minimum and maximum eigenvalues\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Define the figure of merit and orientation of eigenvector for non-maxima suppression\n",
    "    # Make sure to use `get_hessian_eigenvector` (we cannot check all variations of possible answers)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return merit, orientation, vminX, vminY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832bfca-11a0-4ff2-9317-2d97266e7ce9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9526ca3f1f24069c7f76bdb2cf667588",
     "grade": false,
     "grade_id": "cell-571e1cad79b2f9a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's perform a quick sanity check and see if we can extract the middle centerline of Cross200 given a sufficiently large `sigma=3`. Run the following cell to visualize the output and differences between the magnitude and the figure of merit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a505fc-fef1-4701-9fad-8a302c0bd383",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2a3838e6e0ed0d53c39ce92bf3165e0",
     "grade": true,
     "grade_id": "cell-1922fe433eed6095",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Apply Gaussian blurring to the cross image\n",
    "cross_blur = smooth_gaussian(img_cross200, sigma=3)\n",
    "# Compute the Hessian features\n",
    "cross_ridge_feats = np.array(compute_hessian_features(cross_blur))\n",
    "# Compute the gradient features\n",
    "cross_edges_feats = np.array(compute_gradient_features(cross_blur))\n",
    "# Visualize the blurred image, gradient magnitude and the figure of merit\n",
    "image_list = [cross_blur, cross_edges_feats[0], cross_ridge_feats[0]]\n",
    "title_list = ['Blurred Cross200', 'Gradient magnitude', 'Figure of merit']\n",
    "plt.close('all')\n",
    "view2b1 = viewer(image_list, title=title_list, subplots=(1,3), widgets=True, joint_zoom=True)\n",
    "\n",
    "# Sanity checks\n",
    "error_check = False\n",
    "\n",
    "# Figure of merit values expected to be positive\n",
    "if not np.all(cross_ridge_feats[0] >= 0):\n",
    "    print('WARNING!\\nYour figure of merit values should all be positive.')\n",
    "    error_check = True\n",
    "\n",
    "# The cross centerline should be bright\n",
    "if np.mean(cross_ridge_feats[0][100,:] + cross_ridge_feats[0][:,100]) < 35 :\n",
    "    print('WARNING!\\nSeems like your figure of merit has very low merit at the centerline, this is the opposite of what we aim for here.')\n",
    "    error_check = True\n",
    "\n",
    "# Normalised eigenvector norms are within [-1, 1]\n",
    "if np.any(np.abs(cross_ridge_feats[2]) > 1) or np.any(np.abs(cross_ridge_feats[3]) > 1):\n",
    "    print('WARNING!\\nYour eigenvector norms should be in the range [-1, 1].') \n",
    "    error_check = True\n",
    "    \n",
    "if error_check:\n",
    "    print('Make sure your calculation of the eigenvalues are correct. The other steps are similar to Part 1.B.')\n",
    "else :\n",
    "    print('Congratulations! Your hessian features passed the sanity check.\\nRemember that this is not a guarantee that everything is correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4dab9-3db6-4b2b-a259-83e654063395",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "183c9fc0cf00a7826f7d2ee39205470c",
     "grade": false,
     "grade_id": "cell-4f0e4db093f43121",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To close up this exercise, let's get back to our Fundus example. Running the next three cells will show you the output at different steps of your ridge detection pipeline. Given thresholds `tl=10` and `th=35` you should be able to distinguish the major vessels as single ridge lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c2aa7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf909471fb97712f8a05ec7ce286458d",
     "grade": false,
     "grade_id": "cell-391bbcc72cac7c5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Apply Gaussian smoothing and compute Hessian features of the fundus image\n",
    "hessian_blur = smooth_gaussian(img_fundus, sigma=1)\n",
    "hessian_feats = np.array(compute_hessian_features(hessian_blur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d96fba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c294c0eed1bc924e26d3286ddb68af48",
     "grade": false,
     "grade_id": "cell-5088ee1dbe7f4c44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get hessian_feats\n",
    "%put hessian_nms hessian_tlh\n",
    "// Apply the non-maximum suppression with interpolation\n",
    "var hessian_nms = applyNonMaximumSuppressionInterpolation(\n",
    "    new Image(hessian_feats[0]), new Image(hessian_feats[2]), new Image(hessian_feats[3])\n",
    ").toArray()\n",
    "// Perform hysteresis edge tracking\n",
    "var hessian_tlh = thresholdEdgesHysteresis(new Image(hessian_nms), 10, 35).toArray(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf6fc7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0e3f228ac9db848e245db8a5026ae9e",
     "grade": false,
     "grade_id": "cell-78c3d9ab33636091",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Convert JS arrays to numpy\n",
    "hessian_nms = np.array(hessian_nms)\n",
    "hessian_tlh = np.array(hessian_tlh)\n",
    "# Visualize the different steps in the pipeline\n",
    "image_list = [img_fundus, hessian_blur, *hessian_feats[:2], hessian_nms, hessian_tlh]\n",
    "title_list = ['Original', 'Blurred', 'Figure of Merit', 'Eigenvector Orientation', 'NMS', 'Ridges']\n",
    "plt.close('all')\n",
    "view2b2 = viewer(image_list, title=title_list, subplots=(3,2), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d224a82-3928-4a16-9bb3-55f773160081",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c26cfad4d32e10c193a08dac26a369",
     "grade": false,
     "grade_id": "cell-42a0577a6200c6bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "This algorithm you just implemented has no equivalent in OpenCV. Other libraries such as scikit provide [ridge operators](https://scikit-image.org/docs/stable/auto_examples/edges/plot_ridge_filter.html). We invite you to play with them in the following cell, and observe the differences. We hope you will agree that your original ridge detector does a better job than this library, if you spend the time to tune your output, that is :) \n",
    "\n",
    "Also, some of these filters are named after people who worked for our lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6b177-1582-416c-8836-b8991718af3d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Import the ridge filters\n",
    "from skimage.filters import meijering, sato, frangi, hessian\n",
    "\n",
    "# Apply different ridge filters on the fundus image\n",
    "test_img = images_list[2]\n",
    "m = meijering(test_img)\n",
    "s = sato(test_img)\n",
    "f = frangi(test_img)\n",
    "h = hessian(test_img)\n",
    "\n",
    "# Display them\n",
    "plt.close('all')\n",
    "view2b3 = viewer([m, s, f, h], title=['meijering', 'sato', 'frangi', 'hessian'], subplots=(2,2), widgets=True, joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a26dd2-55e5-4cfb-a026-4547d0de82e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4348e9ca2a20f746e217fa5df353981f",
     "grade": false,
     "grade_id": "cell-7f018355c33ebfce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Congratulations on finishing the Feature detection lab !!</b> Hopefully you now understand the differences between edges and ridges, as well as their different use cases. Also, remember OpenCV is made to be fast and practical, sometimes at the expense of the purity we seek in this image processing course.\n",
    "</div>\n",
    "\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/course/view.php?id=463\">Moodle</a>, **in a zip file with the other notebook of this lab.**\n",
    "\n",
    "* Keep the name of the notebook as: *2_Feature_detection.ipynb*,\n",
    "* Name the `zip` file: *Feature_detection_lab.zip*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#c8e1ae",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0
   },
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}